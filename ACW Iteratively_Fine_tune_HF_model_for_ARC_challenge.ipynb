{"cells":[{"cell_type":"markdown","metadata":{"id":"KLLDulPOLMZ4"},"source":["# Fine tune ARC model using huggingface libaries\n","\n","# nlpARC Solver\n","\n","Written by: Jack Cole\n","Mindware Consulting, Inc. \n","Year written: 2022\n","Contact: jackcole@mindware.mobi"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665572433008,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"dsSVcQxex3-v"},"outputs":[],"source":["# reload external modules automatically if they are changed\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665572433008,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"-nnprFhnx3-y"},"outputs":[],"source":["#!pip3 install -U git+https://github.com/arc-community/arc.git@dev"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665572433008,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"piJjdHhtx3-z"},"outputs":[],"source":["# import functools\n","# import random\n","# import time\n","# from arc.interface import Board, BoardPair\n","# from arc.utils.dataset import get_riddles, load_riddle_from_id, get_riddles_from_folder\n","# from arc.augmentations import functional\n","# from arc.augmentations.classes.color import RandomColor\n","# from arc.augmentations.classes.spatial import RandomCropInputAndOuput, RandomDoubleInputBoard, RandomRotate, RandomReflect\n","# from arc.augmentations.classes.noise import Noise\n","# from arc.augmentations.classes.helpers import same_aug_for_all_pairs_helper\n","# from arc.augmentations.vis_helpers import plot_task"]},{"cell_type":"markdown","metadata":{"id":"h3fdjdfrx3-z"},"source":["# Setup for Colab"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665572433009,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"VL5LlLuNx3-0"},"outputs":[],"source":["experiment_id = \"ACW_2022_10_15_1_ARC_180M_DATASET_LT5\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1047,"status":"ok","timestamp":1665572434052,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"JJ3eoT6gLMZ8","outputId":"2eaeac04-404d-459a-80f2-96c50e2dedb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["colab_enabled = False\n","deepspeed_enabled = False\n","deepspeed_config_file = \"ds_config_zero3.json\"\n","import torch\n","print(torch.cuda.is_available())\n","#print(torch.cuda.device_count())\n","#print(torch.cuda.get_device_name(0))\n","#print(torch.cuda.current_device())\n","# cuda version\n","#print(torch.version.cuda)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7756,"status":"ok","timestamp":1665572441807,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"e48gBbdex3-2","outputId":"0294634e-e8f8-4263-f465-a7b03915748b"},"outputs":[{"name":"stderr","output_type":"stream","text":["wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Acer/.netrc\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmindware\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"name":"stdout","output_type":"stream","text":["env: WANDB_LOG_MODEL=false\n"]}],"source":["if colab_enabled:\n","    !pip install wandb\n","!wandb login <your_api_key>\n","\n","import wandb\n","wandb.login()\n","%env WANDB_LOG_MODEL=false\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7064,"status":"ok","timestamp":1665572448868,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"ZRZ1OHZrLMZ-","outputId":"3f8034e4-c4c7-44b7-ee59-155da1aaeb97"},"outputs":[],"source":["if colab_enabled:\n","    if deepspeed_enabled:\n","        !pip install deepspeed\n","    !pip install datasets\n","    !pip install transformers\n","    if deepspeed_enabled:\n","        !pip install transformers[deepspeed]\n","\n","# install widgets for jupyter\n","#!pip install ipywidgets    \n","#!pip install jupyterlab\n","#!pip install jupyterlab_widgets\n","#!jupyter labextension install @jupyter-widgets/jupyterlab-manager\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":871,"status":"ok","timestamp":1665572449727,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"VZ_jiTgRLMZ_","outputId":"fbec6041-4d38-47b5-ca9d-5f1f86598476"},"outputs":[],"source":["#use if on colab and you want to save data to Google Drive\n","if colab_enabled:\n","    from google.colab import drive\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665572449728,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"sLKCTGtbr6vI"},"outputs":[],"source":["# DeepSpeed requires a distributed environment even when only one process is used.\n","# This emulates a launcher in the notebook\n","if deepspeed_enabled:\n","    import os\n","\n","    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n","    os.environ[\"MASTER_PORT\"] = \"9994\"  # modify if RuntimeError: Address already in use\n","    os.environ[\"RANK\"] = \"0\"\n","    os.environ[\"LOCAL_RANK\"] = \"0\"\n","    os.environ[\"WORLD_SIZE\"] = \"1\""]},{"cell_type":"markdown","metadata":{"id":"uD-X3_9VLMaA"},"source":["# Compatible Models\n","\n","Here are a list of models that are comptible with this training method.  You will need to search huggingface to get the exact model name.\n","\n","bart — BartForConditionalGeneration (BART model)\n","bigbird_pegasus — BigBirdPegasusForConditionalGeneration (BigBird-Pegasus model)\n","blenderbot — BlenderbotForConditionalGeneration (Blenderbot model)\n","blenderbot-small — BlenderbotSmallForConditionalGeneration (BlenderbotSmall model)\n","encoder-decoder — EncoderDecoderModel (Encoder decoder model)\n","fsmt — FSMTForConditionalGeneration (FairSeq Machine-Translation model)\n","led — LEDForConditionalGeneration (LED model)\n","longt5 — LongT5ForConditionalGeneration (LongT5 model)\n","m2m_100 — M2M100ForConditionalGeneration (M2M100 model)\n","marian — MarianMTModel (Marian model)\n","mbart — MBartForConditionalGeneration (mBART model)\n","mt5 — MT5ForConditionalGeneration (MT5 model)\n","mvp — MvpForConditionalGeneration (MVP model)\n","nllb — M2M100ForConditionalGeneration (NLLB model)\n","pegasus — PegasusForConditionalGeneration (Pegasus model)\n","plbart — PLBartForConditionalGeneration (PLBart model)\n","prophetnet — ProphetNetForConditionalGeneration (ProphetNet model)\n","t5 — T5ForConditionalGeneration (T5 model)\n","xlm-prophetnet — XLMProphetNetForConditionalGeneration (XLM-ProphetNet model)\n","The model is set in evaluation mode by default using model.eval() (so for instance, dropout modules are deactivated). To train the model, you should first set it back in training mode with model.train()\n"]},{"cell_type":"markdown","metadata":{"id":"havZoFjrx3-7"},"source":["# Set Global Variables and Config"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"elapsed":1215,"status":"ok","timestamp":1665572451300,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"wGm0GeAdLMaB","outputId":"f6e3b62a-c812-46b8-8b61-fdbc0aa6040a"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_NOTEBOOK_NAME=f\"Experiment ACW_2022_10_15_1_ARC_180M_DATASET_LT5 google-long-t5-tglobal-base\"\n","Training file exists\n","validation file exists\n"]},{"data":{"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.13.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>c:\\Users\\Acer\\Desktop\\ARC Challenge\\Experiments\\Experiment ACW - Colab DL 180M Dataset for ARC\\wandb\\run-20221016_134100-12lo814e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/mindware/arc/runs/12lo814e\" target=\"_blank\">ACW_2022_10_15_1_ARC_180M_DATASET_LT5_google-long-t5-tglobal-base</a></strong> to <a href=\"https://wandb.ai/mindware/arc\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/mindware/arc/runs/12lo814e?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x186f76e7c70>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#good for testing to run through more quickly\n","#model_to_fine_tune = \"hf-internal-testing/tiny-random-bart\"\n","\n","#model_to_fine_tune = \"Stancld/longt5-tglobal-large-16384-pubmed-3k_steps\" # 770M parameters\n","#model_to_fine_tune = \"google/long-t5-tglobal-xl\" # 3B parameters\n","#model_to_fine_tune = \"google/long-t5-local-base\" # local attention doesn't perform as well\n","model_to_fine_tune = \"google/long-t5-tglobal-base\"\n","tokenizer_to_use = model_to_fine_tune # \"arc_longt5_tokenizer\"\n","#model_to_fine_tune = \"google/bigbird-pegasus-large-arxiv\"\n","#model_to_fine_tune = \"allenai/led-base-16384\" # longformer encoder decoder - easier to train than bigbird\n","#model_to_fine_tune = \"allenai/led-large-16384-arxiv\" # 459,801,600 parameters\n","#model_to_fine_tune = \"facebook/bart-large-cnn\"\n","#model_to_fine_tune = \"facebook/bart-large\"\n","#model_to_fine_tune = \"facebook/bart-base\"\n","base_model = model_to_fine_tune\n","\n","%env WANDB_NOTEBOOK_NAME = f\"Experiment {experiment_id} {model_to_fine_tune.replace(\"/\", \"-\")}\"\n","\n","'''\n","=-=-=-=-=-=-=-=-=-=-=-\n","iterative mode options\n","=-=-=-=-=-=-=-=-=-=-=-\n","'''\n","# off - no iterative fine tuning\n","# single model - fine tune a single model with the outputs of the previous model + prompt as inputs\n","# chained models - fine tune a single model with the outputs of the previous model as inputs\n","iterative_mode = 'off'  \n","\n","accuracy_filtering_mode = False # filter out items for iterative training that are not accurate enough\n","# if above is false, the following 3 don't apply\n","accuracy_threshold_to_iterate_start = 0.4 # must be at least this accurate to be included in the next iteration\n","accuracy_threshold_to_iterate_current = 0.4\n","accuracy_threshold_step = 0.02 # must be at least this accurate to be included in the next iteration\n","'''\n","=-=-=-=-=-=-=-=-=-=-=-\n","end iterative mode options\n","=-=-=-=-=-=-=-=-=-=-=-\n","'''\n","\n","\n","#model_to_fine_tune = \"./models/6_1_1_1\" # is actually 4 epochs not 6\n","max_input_length = 3600\n","max_output_length = 500\n","epoch_start_up=0 # number of epochs to train for testing the code - it will run this number of epochs and then run the prediction phase on the validation data\n","epoch_start=0 # starting epoch number for training - use this if you want to continue training from a checkpoint\n","epoch_current_count=0 # tracks the current epoch number - similar to epoch_start but is incremented after each epoch\n","epoch_end=20 # ending epoch number for training\n","epoch_step=1 # step size for epochs - train for this number of epochs and then run the prediction phase on the validation data\n","filter_by_token_count = True # filter out items that are too long for the model\n","prediction_temp = 0.0 # temperature for prediction\n","\n","correct_item_count_to_save_model=6 # number of correct items to save that version of the model\n","\n","batch_size = 4 # batch_size of 1 works best for ARC fine tuning training\n","\n","# for eval_batch_size the higher the batch size the more memory is needed; but it runs faster with a higher batch size\n","if colab_enabled:\n","    eval_batch_size = 10\n","else:\n","    eval_batch_size = 20 # this is for iterative training when the training data is run through the model to generate the training data for the next epoch\n","\n","lr = 3.1e-5 # learning rate\n","gradient_checkpointing = True # gradient checkpointing does not work with some models - it can help to reduce memory requirements\n","max_checkpoint = 10 # maximum number of checkpoints to save - this can take up a lot of space if you have a large model\n","\n","grid_starting_row = 4 # where the grid starts in the generated answer\n","output_contains_grid_size = True # if the output contains the grid size\n","\n","if colab_enabled:\n","    experiment_folder='/content/drive/My Drive/Colab Notebooks/Experiment ACW - 180M Dataset for ARC/'\n","else:\n","    experiment_folder='./'\n","#tokenizer_to_use = f\"{experiment_folder}{tokenizer_to_use}\"\n","arc_data_folder = r\"C:\\Users\\Acer\\.arc\\cache\\dataset\\sort_of_ARC_all\" # folder where the ARC data files are located\n","#load the model from the experiment folder\n","#model_to_fine_tune = experiment_folder  + 'models/1_1_1_25'\n","#model_to_fine_tune = r\"C:\\Users\\Acer\\Desktop\\ARC Challenge\\Experiments\\Experiment ACW - Colab DL 180M Dataset for ARC\\resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-17500\"\n","model_to_fine_tune = r\"C:\\Users\\Acer\\Desktop\\ARC Challenge\\Experiments\\Experiment ACW - Colab DL 180M Dataset for ARC\\models\\9_3_3_56\"\n","# use the url to get the dataset if you don't already have it\n","#training_data_file = 'train_plus_copy_onl_none_copy.csv' \n","#training_data_file = 'train_data_len_grid_size_answers_all_output_grid_characteristics_augmente_none_copy_flip_vertically_swap.csv'  #'train_plus_copy_onl_none_copy.csv' \n","#validation_data_file = 'evaluation_data_len_grid_size_answers_all_output_grid_characteristics.csv' \n","training_data_file = 'train_with_letters_none_noise.csv'\n","validation_data_file = 'eval_data_none.csv' \n","evaluation_files=[validation_data_file]\n","# if you want to run the training data through the model, use\n","#evaluation_files=[training_data_file] or evaluation_files=[training_data_file,validation_data_file] for both\n","import os\n","# check to see if training and validation files exist\n","if not os.path.exists(f\"{experiment_folder}{training_data_file}\"):\n","    print(f\"Training file {training_data_file} does not exist\")\n","    exit()\n","else:\n","    print(\"Training file exists\")    \n","if not os.path.exists(f\"{experiment_folder}{validation_data_file}\"):\n","    print(f\"Validation file {validation_data_file} does not exist\")\n","    exit()\n","else:\n","    print(\"validation file exists\")\n","\n","# you can use this in file names for writing output\n","model_name_safe = base_model.replace(\"/\", \"-\")\n","\n","wandb.init(project=\"arc\", name=experiment_id+\"_\"+model_name_safe, config={\"epochs\": epoch_end, \"batch_size\": batch_size, \"train_data_file\": training_data_file})"]},{"cell_type":"markdown","metadata":{"id":"h16h-W9VLMaC"},"source":["# Dataset details\n","The dataset is built, in part, from the original ARC data.  It is formatted in the way that is the most familiar to language models (i.e., like a sentence).  Here is an example prompt:\n","\n","train input1 98889 88288 82228 88288 98889 output1 109 10 10 982 9888992892 8828892892 8222892892 8828892892 9888992892 9999922892 2222228892 8888888992 9999999922 2222222228. input2 23332 33533 35553 33533 23332 output2 109 10 10 235 2333225325 3353325325 3555325325 3353325325 2333225325 2222255325 5555553325 3333333225 2222222255 5555555553. test tinput1 51115 11911 19991 11911 51115 toutput1 \n","\n","The choice of numbers was empirically derived through many experiments.  These experiments compared letters with commas between them, spaces between them, two character chunks, and the same options with numbers.  Numbers without spaces was slightly better than lower case letters without spaces.  With spaces and two character chunks clearly performed worse.  The row separation of a space was also derived from experiments that compared commas, new lines, and spaces.  Each input/output pair is written like a sentence and ends in a period.  This is done to help the model generate an output that has a clear ending.\n","\n","Notice that the output grids have extra numbers before the grid starts.  This is the total grid length in characters, grid width, grid height, unique colors in the order they are encountered.  Ultimately, the grid length and grid size in the final answer is used to generate additional answers by parsing the grid using these predictions.  Sometimes there is a divergence, and one of these alternatively parsed grids will be correct.\n","\n","Example answer:\n"," 109 10 10 519 5111559159 1191159159 1999159159 1191159159 5111559159 5555599159 9999991159 1111111559 5555555599 9999999991. \n"]},{"cell_type":"markdown","metadata":{"id":"Ka2e5dH-x3-9"},"source":["# Set up the GPU"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176,"status":"ok","timestamp":1665572451474,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"KC_HbEUWx3--","outputId":"adbc8548-2578-45d6-bf3b-0d221c48c3c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Oct 16 13:41:02 2022       \n","cuda+-----------------------------------------------------------------------------+\n","\n","| NVIDIA-SMI 516.01       Driver Version: 516.01       CUDA Version: 11.7     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |"]}],"source":["# run nvidia-smi to see if you have a GPU\n","!nvidia-smi\n","\n","# Setting up the device for GPU usage\n","import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"1\"\n","\n","from torch import cuda\n","#print(torch.version.cuda)\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665572451475,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"yumD8Ykqx3--"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n","|  0%   47C    P5    47W / 350W |    998MiB / 24576MiB |     19%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      7256    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n","|    0   N/A  N/A      7804    C+G   ...ser\\Application\\brave.exe    N/A      |\n","|    0   N/A  N/A     10676    C+G   ...here Software\\B4A\\B4A.exe    N/A      |\n","|    0   N/A  N/A     10808    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     14136    C+G   ...e\\root\\Office16\\EXCEL.EXE    N/A      |\n","|    0   N/A  N/A     14916    C+G   ...txyewy\\MiniSearchHost.exe    N/A      |\n","|    0   N/A  N/A     15236    C+G   C:\\Windows\\explorer.exe         N/A      |\n","|    0   N/A  N/A     15584    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n","|    0   N/A  N/A     16400    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n","|    0   N/A  N/A     16424    C+G   ...artMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     16480    C+G   ...370.42\\msedgewebview2.exe    N/A      |\n","|    0   N/A  N/A     19800    C+G   ...zpdnekdrzrea0\\Spotify.exe    N/A      |\n","|    0   N/A  N/A     21824    C+G   ...\\app-1.0.9006\\Discord.exe    N/A      |\n","|    0   N/A  N/A     23504    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n","|    0   N/A  N/A     23700    C+G   ...370.42\\msedgewebview2.exe    N/A      |\n","|    0   N/A  N/A     24588    C+G   ...root\\Office16\\OUTLOOK.EXE    N/A      |\n","|    0   N/A  N/A     26676    C+G   C:\\Windows\\explorer.exe         N/A      |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# import a garbage collector to free up memory\n","import gc\n","\n","def free_memory():\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"R2Zk-YLox3--"},"source":["# Load the Tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["e685dc60ac4944c4874ef51ee1f17303","f81aab2ac1c44c8cb845b5930b439821","ba873aeb8c0448519a23dcd7198220fa","0e26b17557c94ce08550b3a6805e8cce","b79bcbe963f4440ca4cfea35cd191f0a","e0ddd5f1ae2e428690721cc983e008ff","661542f02b0d4858b1925431dad913a7","c733ea5cf8fe4b8c89a097271eff5589","f3c7b8b8ef764040a5f69df7e76ab7b1","e82e5edfc77c43f0ad9113dd7dfa78f5","2de44597f25c4c4ca6fc1051062cb9bb","4215bf0484f9460dbee73d48f5cb5c8c","caf290bdd1ab47f1bc62ab724cb5b3e9","1fb34d70eaf6461bbdba36db45a2999a","6159d356f3644cfbbf317fef27756d61","96dbe96fec8d4df29f82bb979096428e","eb4bdf1b21cd42b9af41d7671ce8e18d","5c390ba7b5c843faa7284fb3ffc309c6","4db5e63b7d624e9c8ab4a9d98005f269","18454d9db3d74bbe9367060bf88513db","67c17f8656904c7a9c0c23b53a5fedae","484209402e6a4ee4b86ccc0775305e62","8b67479e467d4f2aa466e2c595f6c914","f39570f3223f4e079111d3cda6dbb6ca","445103f567a64ba783753d0b90a32f6b","be0828e04c074671a3d496273c5d15b8","06c99d94254c43dd88eec57f52d5f8b7","ebcfb85334fa4168986c40c4e34949d6","78ad2485f6d54e179631359e6db52d11","24b3344c6dd242f2bcf788f87cd6ea54","e28d373b0fb24da29b7e7f1b35691b3f","1f4ce4e9beb143e68016c72d9c2c75f1","2b1b22a2c5e84da3a698d9afe8f13c0b","90b968b6a511495d8443cc5ad3277b14","daf1dca873d34433b8f92a85d9c433f0","7f9f8edbd5f849f982252de0a6499f7c","0685654a1dd6408c8f515da65ed5ddb9","de68bc057a8b426c8a0d810beb28180d","b1b37d4a60d04c8280188745d8f31b23","7d6e024958ac4cf5ae59041d82299da4","efb87782971d437db2bd3ad833026a38","7ccf95c50f8147509c871dcaef5c90bb","8e85189bd1cc4247a95734f906fe0f71","567ca34370c0478f80f4867a782c801c"]},"executionInfo":{"elapsed":1572,"status":"ok","timestamp":1665572453041,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"hn_2HSv9LMaE","outputId":"d1423c2d-05e4-4a36-ca04-ba74565c5069"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading tokenizer for arc_longt5_tokenizer\n"]}],"source":["def load_tokenizer():\n","  global tokenizer\n","  from transformers import AutoTokenizer\n","  print(f\"loading tokenizer for arc_longt5_tokenizer\")\n","  tokenizer = AutoTokenizer.from_pretrained(tokenizer_to_use)\n","\n","load_tokenizer()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":205,"status":"ok","timestamp":1665572453243,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"-raR4BW9x3-_"},"outputs":[],"source":["# tokenize quickly all at once\n","# import pandas as pd\n","# train_df = pd.read_csv(f\"{experiment_folder}{training_data_file}\")\n","# train_df_tokenized = tokenizer(train_df['prompt'].tolist(), padding=True, truncation=True, max_length=max_input_length, return_tensors=\"pt\")\n"]},{"cell_type":"markdown","metadata":{"id":"QuEA8UMeLMaE"},"source":["# Get Token Counts and Filter the data\n","This will use the tokenizer to tokenize the data and will filter the input prompt and correct answers by the length you specified in max_input_length and max_output_length.\n","\n","TODO: Automatically get these characteristics for the model to set max_input_length and max_output_length.  Within limits though, because you don't need 16000 tokens for longt5.  3600 is sufficient for all items on input and 500 on output."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":661,"status":"ok","timestamp":1665572453903,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"WZ-DklZlLMaF"},"outputs":[],"source":["import pandas as pd\n","from datasets import Dataset\n","\n","def filter_file_for_max_tokens(file_name, shuffle=True):\n","    \n","    if \"http\" in file_name:\n","      tdf = file_name\n","    else:\n","      if \"/\" not in file_name:\n","        tdf = f\"{experiment_folder}{file_name}\"\n","      else:\n","        tdf = file_name      \n","\n","    print(f\"filter_file_for_max_tokens {tdf}\")\n","    df = pd.read_csv(tdf)\n","\n","    if filter_by_token_count:\n","        # add the token count columns\n","        #tokenized_prompts = tokenizer(df['prompt'].tolist(), padding=True, truncation=True, max_length=max_input_length, return_tensors=\"pt\")\n","        #df['token_count'] = df['prompt'].apply(lambda x: len(tokenized_prompts['input_ids']))\n","        df['token_count'] = df['prompt'].apply(lambda x: len(tokenizer.encode(x)))\n","        # same for correct answer\n","        df['token_count_correct'] = df['correct_answer'].apply(lambda x: len(tokenizer.encode(x)))\n","\n","        # filter out the examples that are too long\n","        df = df[df['token_count'] <= max_input_length]\n","        df = df[df['token_count_correct'] <= max_output_length]\n","        # fix the index\n","        df = df.reset_index(drop=True)\n","    # randomize the dataset order\n","    if shuffle:\n","        df = df.sample(frac=1).reset_index(drop=True)\n","    return df\n","\n","prefix = \"\"\n","def preprocess_function(examples):\n","    inputs = [prefix + doc for doc in examples[\"prompt\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"correct_answer\"], max_length=max_output_length, truncation=True)\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs    \n","\n","def load_and_process_dataset_from_file(file_name, shuffle=True):\n","    print(f\"load_and_process_dataset_from_file {experiment_folder}{file_name}\")\n","    df = filter_file_for_max_tokens(file_name, shuffle)\n","    print(\"loading dataset from pandas dataframe\")\n","    dataset = Dataset.from_pandas(df)\n","    dataset = dataset.map(preprocess_function, batched=True)\n","    return dataset\n","\n","def load_and_process_datasets(train = training_data_file, eval = validation_data_file):\n","    # load dataset from the dataframes; filter out examples that are too long\n","    # train_dataset = Dataset.from_pandas(filter_file_for_max_tokens(train))\n","    # validation_dataset = Dataset.from_pandas(filter_file_for_max_tokens(eval))\n","    # tokenized_train = train_dataset.map(preprocess_function, batched=True)\n","    # tokenized_eval = validation_dataset.map(preprocess_function, batched=True)\n","    tokenized_train = load_and_process_dataset_from_file(train)\n","    tokenized_eval = load_and_process_dataset_from_file(eval)\n","    return tokenized_train, tokenized_eval"]},{"cell_type":"markdown","metadata":{"id":"wjnsp2rhLMaG"},"source":["# Performs Inference, Data Parsing, and Item Stats\n","\n","TODO: Refactor.  This is messy code. The worst are parse_answers_model1 and get_and_save_predictions."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665572453903,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"e76UwEPDLMaG"},"outputs":[],"source":["import regex as re\n","\n","# split the string into an array of rows and calculate the character by character accuracy between the two arrays\n","def calculate_character_accuracy_by_row(predicted_string, actual_string):\n","    # split the strings by spaces\n","    predicted_string_split = predicted_string.strip().split(' ')\n","    actual_string_split = actual_string.strip().split(' ')\n","    # remove empty arrays\n","    predicted_string_split = remove_empty_arrays(predicted_string_split)\n","    actual_string_split = remove_empty_arrays(actual_string_split)\n","    # calculate character by character accuracy\n","    character_accuracy = 0\n","    for i in range(len(predicted_string_split)):\n","        if i<len(actual_string_split):\n","            character_accuracy += calculate_character_accuracy(predicted_string_split[i], actual_string_split[i])\n","    if len(actual_string_split)==0:\n","      return 0\n","    else:\n","      return character_accuracy / len(actual_string_split)\n","\n","# calculate character by character accuracy\n","def calculate_character_accuracy(predicted_string, actual_string):\n","    predicted_string=predicted_string.strip()\n","    actual_string=actual_string.strip()\n","    # calculate character by character accuracy\n","    character_accuracy = 0\n","    for i in range(len(predicted_string)):\n","        if i<len(actual_string):\n","            if predicted_string[i] == actual_string[i]:\n","                character_accuracy += 1\n","    if len(actual_string)==0:\n","      return 0\n","    else:\n","      return character_accuracy / len(actual_string)\n","\n","# calculate row level accuracy (must by in the correct order)\n","def calculate_row_level_accuracy_ordered(predicted_string, actual_string):\n","    # split the strings by spaces\n","    predicted_string_split = predicted_string.strip().split(' ')\n","    actual_string_split = actual_string.strip().split(' ')\n","    # calculate word content accuracy ignoring order\n","    word_content_accuracy_ignoring_order = 0\n","    for i in range(len(predicted_string_split)):\n","        if i<len(actual_string_split):\n","            if predicted_string_split[i] == actual_string_split[i]:\n","                word_content_accuracy_ignoring_order += 1\n","    if len(actual_string_split)==0:\n","        return 0\n","    else:\n","        return word_content_accuracy_ignoring_order / len(actual_string_split)\n","\n","# calculate row level accuracy (the rows can be in any order)\n","def calculate_row_level_accuracy_unordered(predicted_string, actual_string):\n","    predicted_string=predicted_string.strip()\n","    actual_string=actual_string.strip()\n","    if predicted_string=='':\n","      return 0\n","    # split the strings by spaces\n","    predicted_string_split = predicted_string.split(' ')\n","    actual_string_split = actual_string.split(' ')\n","    # remove empty arrays\n","    predicted_string_split = remove_empty_arrays(predicted_string_split)\n","    actual_string_split = remove_empty_arrays(actual_string_split)\n","    # calculate word content accuracy ignoring order\n","    word_content_accuracy_ignoring_order = 0\n","    for i in range(len(predicted_string_split)):\n","        if i<len(actual_string_split):\n","            # determine if the predicted word is in the actual string\n","            if predicted_string_split[i] in actual_string_split:\n","                word_content_accuracy_ignoring_order += 1\n","    if len(actual_string_split)==0:\n","        return 0\n","    else:\n","        return word_content_accuracy_ignoring_order / len(actual_string_split)\n","\n","#more likely to be correct with variable sized output for rows\n","def trim_rows_to_smallest(grid_rows):\n","    #trim the strings in grid_rows to the smallest length\n","    smallest_length = len(grid_rows[0])\n","    for i in range(len(grid_rows)):\n","        if len(grid_rows[i]) < smallest_length:\n","            smallest_length = len(grid_rows[i])\n","    for i in range(len(grid_rows)):\n","        grid_rows[i] = grid_rows[i][:smallest_length]\n","    return grid_rows\n","\n","# trim / pad to grid size\n","def trim_pad_to_grid_size(grid_rows, grid_row_count, grid_column_count):\n","    #trim the strings in grid_rows to the smallest length\n","    if grid_row_count>30:\n","        grid_row_count=30\n","    if grid_column_count>30:\n","        grid_column_count=30\n","    # drop rows that are beyond the row count\n","    grid_rows = grid_rows[:grid_row_count]\n","    for i in range(grid_row_count):\n","        if i<len(grid_rows):\n","            grid_rows[i] = grid_rows[i][:grid_column_count]\n","            # pad out to grid_column_count with 0'SCRIPT_INFO\n","            zeros_to_add = ''.join(['0' for x in range(grid_column_count - len(grid_rows[i]))])\n","            grid_rows[i] = grid_rows[i] + zeros_to_add\n","        else:\n","            # add some empty row(s) if there are fewer than grid_row_count rows\n","            grid_rows.append(['0' for x in range(grid_column_count)])\n","            # join the rows into a single string\n","            grid_rows[i] = ''.join(grid_rows[i])\n","    return grid_rows\n","\n","#remove empty arrays\n","def remove_empty_arrays(array):\n","    return [x for x in array if x != '']\n","    \n","#remove leading and trailing spaces from all strings in an array\n","def remove_leading_and_trailing_spaces(array):\n","    return [x.strip() for x in array]\n","\n","#split the string by anything other than a space or a number. strip leading or trailing spaces. remove empty arrays.\n","def split_by_non_numbers_and_not_spaces(string):\n","    \"\"\"return a list of numbers split by anything other than numbers and spaces\"\"\"\n","    return remove_leading_and_trailing_spaces(remove_empty_arrays(re.split(r'[^\\d\\s]', string)))\n","\n","# get the output from the string returned by the model\n","def output_string_to_answer(outputs):\n","           #if output_val contains \".\" then get the first part of the string before the \".\"\n","    if \".\" in outputs:\n","        # make sure it is a string\n","        output_val = str(outputs).split(\".\")[0]\n","        #output_val=outputs[0]['summary_texts'].split(\".\")[0]\n","    else:\n","        output_val = str(outputs)\n","        #output_val=outputs[0]['summary_texts']\n","    # trim spaces\n","    output_val = output_val.strip()\n","    return output_val\n","\n","#parse the answers from the large model\n","def parse_answers_model1(outputs):\n","    output_val = output_string_to_answer(outputs)\n","    # check to see if it has the minimum number of words, which is grid_starting_row+2\n","    if len(output_val.split()) >= grid_starting_row+1:\n","        try:\n","            error = False\n","            output_len = int(output_val.split(\" \")[0]) #subtract 1 to account for the period that is removed\n","        except ValueError:\n","            error = True\n","        if error == False:\n","            # if the grid starting column is > 1 then get the words before the grid starting column\n","            if grid_starting_row > 1:\n","                other_preds = output_val.split(\" \")[:grid_starting_row]\n","                # remove first element (the number)\n","                other_preds.pop(0)\n","            else:\n","                other_preds = []\n","            output_val = split_by_non_numbers_and_not_spaces(output_val)[0]\n","            output_val = output_val.split(\" \")[grid_starting_row:]\n","            # reassemble the list of words\n","            output_val = \" \".join(output_val)\n","            try:\n","                output_len = int(output_len)\n","            except ValueError:\n","                output_len = len(output_val)\n","            try:\n","                # if the output is longer than the grid then trim it to the grid sizet            \n","                output_val_len_by_prediction=output_val[:output_len]\n","                output_rows_full_pred_len_limited = output_val_len_by_prediction.split(\" \")\n","                output_rows_full_pred_len_limited=remove_empty_arrays(output_rows_full_pred_len_limited)\n","                output_rows = remove_empty_arrays(output_val.split(\" \"))\n","                #if the last element of output_rows is shorter than the first element, remove the last element.\n","                '''\n","                # if output_rows is a list\n","                if isinstance(output_rows, list):\n","                    if len(output_rows[-1]) < len(output_rows[0]):\n","                        output_rows = output_rows[:-1]\n","                '''\n","                if output_contains_grid_size and other_preds[0].isdigit() and other_preds[1].isdigit():\n","                    # if the output contains the grid size, then trim the output to the grid size\n","                    output_rows = trim_pad_to_grid_size(output_rows, int(other_preds[0]), int(other_preds[1]))\n","                else:\n","                    output_rows = trim_rows_to_smallest(output_rows)\n","                try:\n","                    error = False\n","                    output_len_current=len(output_rows[0])\n","                except IndexError:\n","                    output_val_len_by_prediction=output_val\n","                    output_len=len(output_val)\n","                    # add 0's to other_preds for up to grid_starting_row-1\n","                    other_preds = [0 for i in range(grid_starting_row)]\n","                    output_val_by_grid_size_pred = output_val\n","                if not error:\n","                    output_rows_full_pred_len_limited=trim_rows_to_smallest(output_rows_full_pred_len_limited)\n","                    #recombine the elements of output_rows into a single string.\n","                    output_val_len_by_prediction = \" \".join(output_rows_full_pred_len_limited)     \n","                    output_val_by_grid_size_pred = \" \".join(output_rows)\n","                    #fix row lengths for the first answer\n","                    output_rows_answer1 = output_val.split(\" \")\n","                    output_rows_answer1=trim_rows_to_smallest(output_rows_answer1)\n","                    output_val = \" \".join(output_rows_answer1) \n","                    error=False\n","            except IndexError:\n","                error = True\n","                output_val_len_by_prediction=output_val\n","                output_len=len(output_val)\n","                # add 0's to other_preds for up to grid_starting_row-1\n","                other_preds = [0 for i in range(grid_starting_row)]\n","                output_val_by_grid_size_pred = output_val\n","        else:\n","            error = True\n","            output_val_len_by_prediction=output_val\n","            output_len=len(output_val)\n","            # add 0's to other_preds for up to grid_starting_row-1\n","            other_preds = [0 for i in range(grid_starting_row)]\n","            output_val_by_grid_size_pred = output_val\n","    else:\n","        output_val_len_by_prediction=output_val\n","        output_len=len(output_val)\n","        # add 0's to other_preds for up to grid_starting_row-1\n","        other_preds = [0 for i in range(grid_starting_row)]\n","        output_val_by_grid_size_pred = output_val\n","        error=True\n","    return output_val, output_val_len_by_prediction, output_val_by_grid_size_pred, output_len, other_preds, error\n","\n","# Repeat a string n times with a comma between each repetition. It should also put a number on the end of each repetition.\n","def repeat_string_with_comma(string, n):\n","    return \", \".join([str(i+1) + \"_\" + string for i in range(n)])\n","\n","# not using this function anymore. it is replaced by run_inference\n","# def do_inference(model, input_text, return_error_status=True):\n","#     input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","#     error = False\n","#     try:\n","#         outputs = model.generate(input_ids, temperature=prediction_temp, num_beams=4, num_beam_groups=2, top_k=50, top_p=0.95, early_stopping=True, max_length=max_output_length, repetition_penalty=2.5)\n","#     except IndexError:\n","#         outputs = None\n","#         error = True\n","#         if return_error_status:\n","#             return outputs, error\n","#         else:\n","#             return outputs\n","#     decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","#     # remove all characters that are not numbers, spaces, or commas\n","#     decoded_output = re.sub(r\"[^0-9, ]\", \"\", decoded_output) + \".\"\n","#     if return_error_status:\n","#         return decoded_output, error\n","#     else:\n","#         return decoded_output\n","    \n","\n","def get_and_save_predictions(model, file):\n","    global last_evaluation_df # this holds the results of the last evaluation -- used with chained models\n","    free_memory()\n","    #evaluation_files=[validation_data_file]\n","    base_path=f\"{experiment_folder}\"\n","    sum_correct_answer=0\n","    sum_correct_answer_by_actual_len=0\n","    sum_correct_answer_len=0\n","    sum_correct_answer_pred_len=0\n","    sum_correct_answer_by_pred_grid_size=0\n","    sum_other_preds=[]\n","    sum_item_character_accuracy_ordered_unmodified=0\n","    sum_item_character_accuracy_ordered_unmodified_first_half=0\n","    sum_item_character_accuracy_ordered_unmodified_second_half=0\n","    sum_item_character_accuracy_ordered_by_grid_size_pred=0\n","    sum_item_character_accuracy_ordered_by_len_pred=0\n","    sum_item_character_accuracy_ordered_by_len_actual=0\n","    sum_row_accuracy_ordered=0\n","    sum_row_accuracy_unordered=0\n","    solved_items=[]\n","    for i in range(grid_starting_row-1):\n","        sum_other_preds.append(0)\n","\n","    #data_to_evaluate=filter_file_for_max_tokens(file)\n","    data_to_evaluate = run_inference(model, file, False)\n","    free_memory()\n","    # remove the extension from file\n","    file_name_minus_extensions = file.split(\"/\")[-1].split(\".\")[0]\n","    result_file_name = os.path.join(base_path, f\"{file_name_minus_extensions}{model_name_safe}_{epoch_current_count}_epochs_{prediction_temp}_temp_{accuracy_threshold_to_iterate_current}_acc_threshold_batchsize_1_results.csv\")\n","    #iterate through the rows in the dataframe\n","    for i, row in data_to_evaluate.iterrows():\n","        arc_fn=row[\"id\"]\n","        # check to see if data_to_evaluate contains the column \"augmentation\"\n","        aug = \"none\"\n","        if \"augmentation\" in data_to_evaluate.columns:\n","            aug = row[\"augmentation\"]\n","        prompt = row[\"prompt\"]\n","        correct_answer = row[\"correct_answer\"]\n","        #print(f\"Prompt: {prompt}\")\n","        #print(f\"Correct Answer: {correct_answer}\")\n","        outputs = row['predictions']    #, error = do_inference(model, prompt)\n","        #Print(f\"Generated Answer: {outputs}\")\n","        with open(result_file_name, 'a') as f:\n","            answer_no_non_programmatic_len_limit, answer_len_limit_by_prediction, answer_grid_size_by_prediction, output_len, other_preds, error = parse_answers_model1(outputs)\n","            correct_answer=correct_answer.strip().replace(\".\", \"\") #.replace(\" \", \"\").replace(\".\", \"\")\n","            correct_other_preds = correct_answer.split(\" \")[0:grid_starting_row]\n","            correct_len = int(correct_other_preds[0])\n","            #drop first item (length of answer)\n","            correct_other_preds = correct_other_preds[1:]\n","            #remove other preds from the correct answer\n","            correct_answer = correct_answer.split(\" \")[grid_starting_row:len(correct_answer.split(\" \"))]\n","            correct_answer = \" \".join(correct_answer)\n","\n","            #don't calc any stats if there is an error\n","            if error==False:\n","                #make a boolean comparison of all items\n","                correct_other_preds_bool = [1 if x == y else 0 for x, y in zip(correct_other_preds, other_preds)]\n","                output_val_len_limited_by_correct_answer=answer_no_non_programmatic_len_limit[:len(correct_answer)]\n","                #convert boolean to number for csv\n","                correct_answer_bylen_bool=1 if correct_answer==output_val_len_limited_by_correct_answer else 0\n","                correct_answer_bool=1 if correct_answer==answer_no_non_programmatic_len_limit else 0\n","                correct_answer_bypredlen_bool=1 if correct_answer==answer_len_limit_by_prediction else 0\n","                correct_answer_bypredgrid_bool=1 if correct_answer==answer_grid_size_by_prediction else 0\n","                if correct_answer_bool or correct_answer_bylen_bool or correct_answer_bypredlen_bool or correct_answer_bypredgrid_bool:\n","                    solved_items.append(arc_fn)\n","                sum_correct_answer+=correct_answer_bool\n","                sum_correct_answer_by_actual_len+=correct_answer_bylen_bool\n","                sum_correct_answer_pred_len+=correct_answer_bypredlen_bool\n","                sum_correct_answer_by_pred_grid_size+=correct_answer_bypredgrid_bool\n","                correct_answer_len=1 if correct_len==output_len else 0\n","                sum_correct_answer_len+=correct_answer_len\n","                sum_other_preds=[x+y for x, y in zip(sum_other_preds, correct_other_preds_bool)]\n","                current_item_character_accuracy_ordered_unmodified=calculate_character_accuracy_by_row(answer_no_non_programmatic_len_limit, correct_answer)\n","                sum_item_character_accuracy_ordered_unmodified+=current_item_character_accuracy_ordered_unmodified\n","                sum_item_character_accuracy_ordered_unmodified_first_half+=calculate_character_accuracy_by_row(answer_no_non_programmatic_len_limit[0:int(len(answer_no_non_programmatic_len_limit)/2)], correct_answer[0:int(len(correct_answer)/2)])\n","                sum_item_character_accuracy_ordered_unmodified_second_half+=calculate_character_accuracy_by_row(answer_no_non_programmatic_len_limit[int(len(answer_no_non_programmatic_len_limit)/2):len(answer_no_non_programmatic_len_limit)], correct_answer[int(len(correct_answer)/2):len(correct_answer)])\n","                current_item_character_accuracy_ordered_by_grid_size_pred=calculate_character_accuracy_by_row(answer_grid_size_by_prediction, correct_answer)\n","                sum_item_character_accuracy_ordered_by_grid_size_pred+=current_item_character_accuracy_ordered_by_grid_size_pred\n","                current_item_character_accuracy_ordered_by_len_pred=calculate_character_accuracy_by_row(answer_len_limit_by_prediction, correct_answer)\n","                sum_item_character_accuracy_ordered_by_len_pred+=current_item_character_accuracy_ordered_by_len_pred\n","                current_item_character_accuracy_ordered_by_len_actual=calculate_character_accuracy_by_row(output_val_len_limited_by_correct_answer, correct_answer)\n","                sum_item_character_accuracy_ordered_by_len_actual+=current_item_character_accuracy_ordered_by_len_actual\n","                current_row_accuracy_ordered=calculate_row_level_accuracy_ordered(answer_no_non_programmatic_len_limit, correct_answer)\n","                sum_row_accuracy_ordered+=current_row_accuracy_ordered\n","                current_row_accuracy_unordered=calculate_row_level_accuracy_unordered(answer_no_non_programmatic_len_limit, correct_answer)\n","                sum_row_accuracy_unordered+=current_row_accuracy_unordered\n","\n","                #if writing the first line, write the headers\n","                if i==0:\n","                    if grid_starting_row>1:\n","                    # remove the curly braces for the headers\n","                        other_preds_column_titles = repeat_string_with_comma(\"other_preds_string\", grid_starting_row-1)\n","                        correct_other_preds_string_column_titles = repeat_string_with_comma(\"correct_other_preds_string\", grid_starting_row-1)\n","                        correct_other_preds_bool_column_titles = repeat_string_with_comma(\"correct_other_preds_bool\", grid_starting_row-1)\n","                        # some of the headers don't correspond exactly to the variable names for interpretability\n","                        header_string='{arc_fn},{augmentation},{prompt},{correct_answer},{gen_answer_no_non_programmatic_len_limit},{gen_answer_len_limit_by_prediction},{gen_answer_grid_size_by_prediction},{gen_answer_len_limited_by_correct_answer_len},{correct_answer_len},{predicted_output_len},{pred_len_equals_actual_len_bool},'+other_preds_column_titles+','+correct_other_preds_string_column_titles+','+correct_other_preds_bool_column_titles+',{pred_answer_unmodified_equals_correct_answer_bool},{pred_answer_parsed_by_correct_answer_len_equals_correct_answer_bool},{pred_answer_parsed_by_pred_grid_size_equals_correct_answer_bool},{pred_answer_parsed_by_pred_len_equals_correct_answer_bool},{current_item_character_accuracy_ordered_unmodified},{current_item_character_accuracy_ordered_by_grid_size_pred},{current_item_character_accuracy_ordered_by_len_pred},{current_item_character_accuracy_ordered_by_len_actual},{current_row_accuracy_ordered},{current_row_accuracy_unordered},{raw_unparsed_prediction}\\n'\n","                    else:\n","                        header_string='{arc_fn},{augmentation},{prompt},{correct_answer},{gen_answer_no_non_programmatic_len_limit},{gen_answer_len_limit_by_prediction},{gen_answer_len_limited_by_correct_answer_len},{correct_answer_len},{predicted_output_len},{pred_len_equals_actual_len_bool},{pred_answer_unmodified_equals_correct_answer_bool},{pred_answer_parsed_by_correct_answer_len_equals_correct_answer_bool},{pred_answer_parsed_by_pred_len_equals_correct_answer_bool},{current_item_character_accuracy_ordered_unmodified},{current_item_character_accuracy_ordered_by_len_pred},{current_item_character_accuracy_ordered_by_len_actual},{current_row_accuracy_ordered},{current_row_accuracy_unordered},{raw_unparsed_prediction}\\n'\n","                    # write the header_string\n","                    header_string = header_string.replace(\"{\", \"\").replace(\"}\", \"\")\n","                    f.write(header_string)\n","                other_preds_string = \",\".join(str(x) for x in other_preds)\n","                correct_other_preds_string = \",\".join(str(x) for x in correct_other_preds)\n","                correct_other_preds_bool_string = \",\".join(str(x) for x in correct_other_preds_bool)\n","                if grid_starting_row>1:\n","                    #{other_preds_string},{correct_other_preds_string},{sum_other_preds_string}\n","                    string_to_write=f\"{arc_fn},{aug},{prompt},{correct_answer},{answer_no_non_programmatic_len_limit},{answer_len_limit_by_prediction},{answer_grid_size_by_prediction},{output_val_len_limited_by_correct_answer},{correct_len},{output_len},{correct_answer_len},{other_preds_string},{correct_other_preds_string},{correct_other_preds_bool_string},{correct_answer_bool},{correct_answer_bylen_bool},{correct_answer_bypredgrid_bool},{correct_answer_bypredlen_bool},{current_item_character_accuracy_ordered_unmodified},{current_item_character_accuracy_ordered_by_grid_size_pred},{current_item_character_accuracy_ordered_by_len_pred},{current_item_character_accuracy_ordered_by_len_actual},{current_row_accuracy_ordered},{current_row_accuracy_unordered},{outputs}\\n\"\n","                else:\n","                    string_to_write=f\"{arc_fn},{aug},{prompt},{correct_answer},{answer_no_non_programmatic_len_limit},{answer_len_limit_by_prediction},{output_val_len_limited_by_correct_answer},{correct_len},{output_len},{correct_answer_len},{correct_answer_bool},{correct_answer_bylen_bool},{correct_answer_bypredlen_bool},{current_item_character_accuracy_ordered_unmodified},{current_item_character_accuracy_ordered_by_len_pred},{current_item_character_accuracy_ordered_by_len_actual},{current_row_accuracy_ordered},{current_row_accuracy_unordered},{outputs}\\n\"\n","                string_to_write=string_to_write.encode('ascii', 'ignore').decode('ascii') #occasionally crashed in the past due to unicode characters\n","                f.write(string_to_write)\n","            else: # unable to correctly parse the answer; just write the outputs unmodified\n","                f.write(f\"{arc_fn},{aug},{prompt},{correct_answer},{output_string_to_answer(outputs)}\\n\")\n","                #write the sums\n","        last_evaluation_df = pd.read_csv(result_file_name)\n","    with open(result_file_name, 'a') as f:\n","        #replace the unicode characters with ascii in string_to_write\n","        sum_other_preds_string = \",\".join(str(x) for x in sum_other_preds)\n","        sum_other_preds_column_titles = repeat_string_with_comma(\"sum_other_preds\", grid_starting_row-1)\n","        string_to_write=\"\\n\"+sum_other_preds_column_titles+\",{sum_correct_answer_len},{avg_item_character_accuracy_ordered_unmodified},{avg_item_character_accuracy_ordered_by_grid_size_pred},{avg_item_character_accuracy_ordered_unmodified_first_half},{avg_item_character_accuracy_ordered_unmodified_second_half},{avg_item_character_accuracy_ordered_by_len_pred},{avg_item_character_accuracy_ordered_by_len_actual},{avg_row_accuracy_ordered},{avg_row_accuracy_unordered},{sum_correct_answer},{sum_correct_answer_by_actual_len},{sum_correct_answer_pred_len},{sum_correct_answer_by_pred_grid_size}\\n\".replace(\"{\", \"\").replace(\"}\", \"\")\n","        f.write(string_to_write)\n","        # divide the character accuracy and row accuracy by the number of items\n","        # get number of items in data_to_evaluate\n","        num_items_in_data_to_evaluate = len(data_to_evaluate)\n","        sum_item_character_accuracy_ordered_unmodified/=num_items_in_data_to_evaluate\n","        sum_item_character_accuracy_ordered_by_grid_size_pred/=num_items_in_data_to_evaluate\n","        sum_item_character_accuracy_ordered_by_len_pred/=num_items_in_data_to_evaluate\n","        sum_item_character_accuracy_ordered_by_len_actual/=num_items_in_data_to_evaluate\n","        sum_item_character_accuracy_ordered_unmodified_first_half/=num_items_in_data_to_evaluate\n","        sum_item_character_accuracy_ordered_unmodified_second_half/=num_items_in_data_to_evaluate\n","        sum_row_accuracy_ordered/=num_items_in_data_to_evaluate\n","        sum_row_accuracy_unordered/=num_items_in_data_to_evaluate\n","        wandb.log({\"epoch_current_count\" : epoch_current_count, \"sum_correct_answer\": sum_correct_answer, \"sum_correct_answer_by_actual_len\": sum_correct_answer_by_actual_len, \"sum_correct_answer_pred_len\": sum_correct_answer_pred_len, \"sum_correct_answer_by_pred_grid_size\": sum_correct_answer_by_pred_grid_size, \"sum_item_character_accuracy_ordered_unmodified\": sum_item_character_accuracy_ordered_unmodified, \"sum_item_character_accuracy_ordered_by_grid_size_pred\": sum_item_character_accuracy_ordered_by_grid_size_pred, \"sum_item_character_accuracy_ordered_by_len_pred\": sum_item_character_accuracy_ordered_by_len_pred, \"sum_item_character_accuracy_ordered_by_len_actual\": sum_item_character_accuracy_ordered_by_len_actual, \"sum_row_accuracy_ordered\": sum_row_accuracy_ordered, \"sum_row_accuracy_unordered\": sum_row_accuracy_unordered, \"solved_items\" : len(solved_items)})\n","        string_to_write=f\"{sum_other_preds_string},{sum_correct_answer_len},{sum_item_character_accuracy_ordered_unmodified},{sum_item_character_accuracy_ordered_by_grid_size_pred},{sum_item_character_accuracy_ordered_unmodified_first_half},{sum_item_character_accuracy_ordered_unmodified_second_half},{sum_item_character_accuracy_ordered_by_len_pred},{sum_item_character_accuracy_ordered_by_len_actual},{sum_row_accuracy_ordered},{sum_row_accuracy_unordered},{sum_correct_answer},{sum_correct_answer_by_actual_len},{sum_correct_answer_pred_len},{sum_correct_answer_by_pred_grid_size}\\n\"\n","        f.write(string_to_write)\n","    return sum_correct_answer, sum_correct_answer_by_actual_len, sum_correct_answer_pred_len, sum_correct_answer_by_pred_grid_size, sum_correct_answer_len, sum_other_preds_string, data_to_evaluate, sum_item_character_accuracy_ordered_unmodified, sum_item_character_accuracy_ordered_by_grid_size_pred, sum_item_character_accuracy_ordered_by_len_pred, sum_item_character_accuracy_ordered_by_len_actual, sum_row_accuracy_ordered, sum_row_accuracy_unordered, solved_items, error"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":192,"status":"ok","timestamp":1665572454093,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"bAtEsQkox3_D"},"outputs":[],"source":["#get_and_save_predictions(model, evaluation_files[1])"]},{"cell_type":"markdown","metadata":{"id":"EV0wkG80LMaJ"},"source":["# Train the Model and Related Functions\n","\n","The training will train for epoch_steps and then will run the validation data through the model to generate the outputs and custom stats.  This is saved to a file after every epoch_steps.  The model is also saved after every epoch_steps.  "]},{"cell_type":"markdown","metadata":{"id":"6Ao1ZMQvLMaI"},"source":["Functions to Train and Save Overall Custom Stats"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665572454093,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"z8wms9l4LMaI"},"outputs":[],"source":["#from transformers.utils.dummy_tf_objects import TFDebertaV2ForSequenceClassification\n","#from distutils.command.config import config\n","\n","# need to combine the answers from the last evaluation run with the prompts to train the next model\n","def create_new_evaluation_dataset_for_chained_models(parse_prior_answers=True):\n","    global last_evaluation_df\n","    # combine the columns prompt and raw_unparsed_prediction\n","    # if the dataframe does not contain the column prompt_original, then it is the first model in the chain, so save it to prompt_original\n","    if 'prompt_original' not in last_evaluation_df.columns:\n","        last_evaluation_df['prompt_original'] = last_evaluation_df['prompt']\n","    if parse_prior_answers:\n","        last_evaluation_df['prompt'] = last_evaluation_df['prompt_original'] + last_evaluation_df['raw_unparsed_prediction']\n","    else:\n","        last_evaluation_df['prompt'] = last_evaluation_df['prompt'] + last_evaluation_df['raw_unparsed_prediction']\n","    #last_evaluation_df['prompt'] = last_evaluation_df['prompt'].apply(lambda x: x.replace(\"  \", \" \").replace(\"  \", \" \"))\n","    # drop rows where prompt is blank\n","    #last_evaluation_df = last_evaluation_df[last_evaluation_df['prompt'].str.strip() != '']\n","    # write to file\n","    new_validation_data_file = f\"evaluation_dataset_for_chained_models_{epoch_current_count-epoch_step}.csv\"\n","    last_evaluation_df.to_csv(f\"{experiment_folder}{new_validation_data_file}\", index=False)\n","    return new_validation_data_file\n","\n","def create_new_iterative_training_dataset():\n","    print(\"create_new_iterative_training_dataset\")\n","    if (epoch_current_count<epoch_step+1 or iterative_mode=='off') or (iterative_mode=='chained models' and epoch_current_count==0):\n","        return load_and_process_datasets()\n","    \n","    # run inference on the training data; run do_inference on the training data \"prompt\"\n","    if \"http\" not in training_data_file:\n","      if \"/\" not in training_data_file:\n","        tdf = f\"{experiment_folder}{training_data_file}\"\n","      else:\n","        tdf = training_data_file\n","    else:\n","      tdf = training_data_file\n","    print(\"create_new_iterative_training_dataset: tdf\", tdf)\n","    training_df = filter_file_for_max_tokens(tdf, False)\n","    # copy the training data to a new dataframe\n","    #new_training_df = training_df.copy()\n","    new_training_df = run_inference(model, tdf, False)\n"," \n","    # combine the prompt and the results\n","    new_training_df['prompt'] = new_training_df['prompt'] + new_training_df['results']\n","    new_training_df['prompt'] = new_training_df['prompt'].apply(lambda x: x.replace(\"  \", \" \").replace(\"  \", \" \"))\n","    \n","    unflitered_new_df = new_training_df.copy()\n","    # filter out the items that have accuracy of > accuracy_threshold_to_iterate_current\n","    if accuracy_filtering_mode:\n","      new_training_df = new_training_df[new_training_df[\"accuracy\"]>=accuracy_threshold_to_iterate_current]\n","\n","    new_training_file = f\"train_{epoch_current_count-epoch_step}_epoch_start.csv\" \n","    unfiltered_new_training_file = f\"train_{epoch_current_count-epoch_step}_epoch_start_unfiltered.csv\"\n","    # add the items from the new_training_df to the training_df\n","    if iterative_mode!='chained models': # chained models don't include the original training data\n","        training_df = pd.concat([training_df, new_training_df])\n","        training_df.to_csv(f\"{experiment_folder}{new_training_file}\", index=False)\n","    else:\n","        new_training_df.to_csv(f\"{experiment_folder}{new_training_file}\", index=False)\n","\n","    unfiltered_new_training_df = pd.concat([training_df, unflitered_new_df])\n","    unfiltered_new_training_df.to_csv(f\"{experiment_folder}{unfiltered_new_training_file}\", index=False)\n","\n","    # need to save the new validation file as well\n","    # also need option to continue adding to the training file instead of removing the old one\n","    print(\"end create_new_iterative_training_dataset\")\n","    #iterative_mode = 'off'  # 'single model' or 'chained models'\n","    if not accuracy_filtering_mode:\n","        new_training_file = unfiltered_new_training_file\n","    if iterative_mode=='chained models':\n","        validation_data_file = create_new_evaluation_dataset_for_chained_models(True)\n","    return load_and_process_datasets(new_training_file, validation_data_file)\n","\n","def save_metrics(trainer, train_result, tokenized_train, tokenized_eval):\n","   # compute train results\n","    metrics = train_result.metrics\n","    max_train_samples = len(tokenized_train)\n","    metrics[\"train_samples\"] = min(max_train_samples, len(tokenized_train))\n","\n","    # save train results\n","    trainer.log_metrics(\"train\", metrics)\n","    trainer.save_metrics(\"train\", metrics)\n","\n","    # compute evaluation results\n","    metrics = trainer.evaluate()\n","    max_val_samples = len(tokenized_eval)\n","    metrics[\"eval_samples\"] = min(max_val_samples, len(tokenized_eval))\n","\n","    # save evaluation results\n","    trainer.log_metrics(\"eval\", metrics)\n","    trainer.save_metrics(\"eval\", metrics)\n","\n","def train_for_epochs_and_calc_totals(epochs_to_train, epoch_current_count, stats_obj):\n","    print(f\"training for {epochs_to_train} epochs with batch size {batch_size}\")\n","\n","    free_memory()\n","\n","    if iterative_mode=='chained models':\n","        load_tokenizer()\n","        load_model() # load a fresh model each time\n","    \n","    global accuracy_threshold_to_iterate_current, accuracy_threshold_step\n","    accuracy_threshold_to_iterate_current += accuracy_threshold_step\n","\n","    epoch_current_count+=epochs_to_train\n","    tokenized_train, tokenized_eval = create_new_iterative_training_dataset()\n","    # https://huggingface.co/docs/transformers/v4.21.2/en/main_classes/trainer#transformers.TrainingArguments\n","    the_output_dir = f\"{experiment_folder if not colab_enabled else './'}results{experiment_id}\"\n","    if deepspeed_enabled:\n","        training_args = Seq2SeqTrainingArguments(\n","            report_to = 'wandb',                     # enable logging to W&B\n","            output_dir=the_output_dir,              # output directory\n","            evaluation_strategy=\"epoch\",\n","            learning_rate=lr,\n","            per_device_train_batch_size=batch_size,\n","            per_device_eval_batch_size=batch_size,\n","            weight_decay=0.01,\n","            save_total_limit=max_checkpoint, # save manually\n","            num_train_epochs=epochs_to_train,\n","            fp16=False,\n","            seed=42,\n","            deepspeed=f\"{experiment_folder}{deepspeed_config_file}\",\n","        )\n","    else:\n","        training_args = Seq2SeqTrainingArguments(\n","            report_to = 'wandb',                     # enable logging to W&B\n","            output_dir=the_output_dir,              # output directory\n","            evaluation_strategy=\"epoch\",\n","            learning_rate=lr,\n","            per_device_train_batch_size=batch_size,\n","            per_device_eval_batch_size=batch_size,\n","            weight_decay=0.01,\n","            save_total_limit=max_checkpoint, # save manually\n","            num_train_epochs=epochs_to_train,\n","            fp16=False,\n","            seed=42,\n","        )\n","    trainer = Seq2SeqTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_train,\n","        eval_dataset=tokenized_eval,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","    )\n","    \n","    #trainer.evaluate()\n","    train_result = trainer.train()\n","    save_metrics(trainer, train_result, tokenized_train, tokenized_eval)\n","    # iterate through the evaluation files\n","    for file in evaluation_files:\n","        current_correct_count, current_correct_by_len_count, correct_answer_by_predlen_count, current_correct_by_grid_size_count, correct_pred_len, correct_other_pred, evaluation_df_and_results, character_accuracy, sum_item_character_accuracy_ordered_by_grid_size_pred, sum_item_character_accuracy_ordered_by_len_pred, sum_item_character_accuracy_ordered_by_len_actual, sum_row_accuracy_ordered, sum_row_accuracy_unordered, solved_items, error = get_and_save_predictions(model, file)\n","        if error==False:\n","            stats_obj[file].loc[len(stats_obj[file])]=[epoch_current_count,  current_correct_count, current_correct_by_len_count, correct_answer_by_predlen_count, current_correct_by_grid_size_count, correct_pred_len, correct_other_pred, character_accuracy, sum_item_character_accuracy_ordered_by_grid_size_pred, sum_item_character_accuracy_ordered_by_len_pred, sum_item_character_accuracy_ordered_by_len_actual, sum_row_accuracy_ordered, sum_row_accuracy_unordered, solved_items]\n","            # correct_counts.append(current_correct_count)\n","            # correct_counts_len.append(current_correct_by_len_count)\n","            epoch_current.append(epoch_current_count-epochs_to_train)\n","            # correct_counts_pred_len.append(correct_pred_len)\n","            # correct_counts_bypred_len.append(correct_answer_by_predlen_count)\n","            # correct_counts_other_preds.append(correct_other_pred)\n","            # correct_counts_by_grid_size.append(current_correct_by_grid_size_count)\n","            # character_level_accuracy.append(character_accuracy)\n","            # character_level_accuracy_by_grid_size_pred.append(sum_item_character_accuracy_ordered_by_grid_size_pred)\n","            # character_level_accuracy_by_len_pred.append(sum_item_character_accuracy_ordered_by_len_pred)\n","            # character_level_accuracy_by_len_actual.append(sum_item_character_accuracy_ordered_by_len_actual)\n","            # row_level_accuracy_ordered.append(sum_row_accuracy_ordered)\n","            # row_level_accuracy_unordered.append(sum_row_accuracy_unordered)\n","            # correct_items.append(solved_items)\n","            # if any of the most recent correct counts are > 0 then save to a new folder\n","            index = len(stats_obj[file])-1\n","            if iterative_mode==\"chained models\" or stats_obj[file]['correct_counts'][index]>=correct_item_count_to_save_model or stats_obj[file]['correct_counts_bypred_len'][index]>=correct_item_count_to_save_model or stats_obj[file]['correct_counts_by_grid_size'][index]>=correct_item_count_to_save_model:\n","                if iterative_mode==\"chained models\":\n","                    model.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}\")\n","                    tokenizer.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}\")\n","                else:    \n","                    model.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}_{stats_obj[file]['correct_counts'][index]}_{stats_obj[file]['correct_counts_bypred_len'][index]}_{stats_obj[file]['correct_counts_by_grid_size'][index]}\")\n","                    tokenizer.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}_{stats_obj[file]['correct_counts'][index]}_{stats_obj[file]['correct_counts_bypred_len'][index]}_{stats_obj[file]['correct_counts_by_grid_size'][index]}\")\n","            else:\n","                model.save_pretrained(f\"{experiment_folder}\")\n","                tokenizer.save_pretrained(f\"{experiment_folder}\")\n","            save_data_and_stats(stats_obj, file)\n","\n","def save_data_and_stats(stats_obj, file):\n","    # results file\n","    if len(stats_obj[file])>0:\n","        # remove extension from file name\n","        file_name_minus_extension = file.split('.')[0]\n","        results_file = f\"{file_name_minus_extension}{model_name_safe}_final_results.csv\"\n","        # if file exists then set a variable\n","        if os.path.isfile(os.path.join(experiment_folder, results_file)):\n","            file_exists = True\n","        else:\n","            file_exists = False\n","        #write the correct_counts and correct_counts_len to a file final_results.csv\n","        with open(os.path.join(experiment_folder, results_file), 'a') as f:\n","            #write the column labels\n","            if not file_exists:\n","                f.write('model_name,epoch_start,epoch_end,epoch_step,batch_size,lr,epoch_step')\n","                f.write(f\"{model_to_fine_tune},{epoch_start},{epoch_end},{epoch_step},{batch_size},{lr},{epoch_step}\\n\")\n","                # label the columns\n","                correct_other_preds_column_titles = repeat_string_with_comma(\"other_preds_string\", grid_starting_row-1)\n","                f.write(f\"epoch,correct_count,correct_count_by_len,correct_by_pred_len,correct_pred_len,correct_answer_by_grid_size,\"+correct_other_preds_column_titles+\",cell_level_accuracy,cell_level_accuracy_by_grid_size_pred,cell_level_accuracy_by_pred_len,cell_level_accuracy_by_correct_ans_len,row_level_accuracy_ordered,row_level_accuracy_unordered,solved_items\\n\")\n","            i = len(stats_obj[file])-1\n","            try:\n","                # the last item in correct_counts_pred_len\n","                curr_pred_len_correct=stats_obj[file]['correct_counts_pred_len'][i]\n","            except:\n","                curr_pred_len_correct=0\n","            \n","            epochval=epoch_current[i]\n","            f.write(f\"{epochval},{stats_obj[file]['correct_counts'][i]},{stats_obj[file]['correct_counts_len'][i]},{stats_obj[file]['correct_counts_bypred_len'][i]},{stats_obj[file]['correct_counts_pred_len'][i]},{stats_obj[file]['correct_counts_by_grid_size'][i]},{stats_obj[file]['correct_counts_other_preds'][i]},{stats_obj[file]['character_level_accuracy'][i]},{stats_obj[file]['character_level_accuracy_by_grid_size_pred'][i]},{stats_obj[file]['character_level_accuracy_by_len_pred'][i]},{stats_obj[file]['character_level_accuracy_by_len_actual'][i]},{stats_obj[file]['row_level_accuracy_ordered'][i]},{stats_obj[file]['row_level_accuracy_unordered'][i]},{','.join(stats_obj[file]['correct_items'][i])}\")\n","            f.write(\"\\n\")"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665572454094,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"wzTYPS1-x3_F"},"outputs":[],"source":["# save the stats object if something goes wrong\n","\n","# epochs_to_train = 2\n","# # iterate through the evaluation files\n","# for file in evaluation_files:\n","#     current_correct_count, current_correct_by_len_count, correct_answer_by_predlen_count, current_correct_by_grid_size_count, correct_pred_len, correct_other_pred, evaluation_df_and_results, character_accuracy, sum_item_character_accuracy_ordered_by_grid_size_pred, sum_item_character_accuracy_ordered_by_len_pred, sum_item_character_accuracy_ordered_by_len_actual, sum_row_accuracy_ordered, sum_row_accuracy_unordered, solved_items, error = get_and_save_predictions(model, file)\n","#     if error==False:\n","#         stats_obj[file].loc[len(stats_obj[file])]=[epoch_current_count,  current_correct_count, current_correct_by_len_count, correct_answer_by_predlen_count, current_correct_by_grid_size_count, correct_pred_len, correct_other_pred, character_accuracy, sum_item_character_accuracy_ordered_by_grid_size_pred, sum_item_character_accuracy_ordered_by_len_pred, sum_item_character_accuracy_ordered_by_len_actual, sum_row_accuracy_ordered, sum_row_accuracy_unordered, solved_items]\n","#         # correct_counts.append(current_correct_count)\n","#         # correct_counts_len.append(current_correct_by_len_count)\n","#         epoch_current.append(epoch_current_count-epochs_to_train)\n","#         # correct_counts_pred_len.append(correct_pred_len)\n","#         # correct_counts_bypred_len.append(correct_answer_by_predlen_count)\n","#         # correct_counts_other_preds.append(correct_other_pred)\n","#         # correct_counts_by_grid_size.append(current_correct_by_grid_size_count)\n","#         # character_level_accuracy.append(character_accuracy)\n","#         # character_level_accuracy_by_grid_size_pred.append(sum_item_character_accuracy_ordered_by_grid_size_pred)\n","#         # character_level_accuracy_by_len_pred.append(sum_item_character_accuracy_ordered_by_len_pred)\n","#         # character_level_accuracy_by_len_actual.append(sum_item_character_accuracy_ordered_by_len_actual)\n","#         # row_level_accuracy_ordered.append(sum_row_accuracy_ordered)\n","#         # row_level_accuracy_unordered.append(sum_row_accuracy_unordered)\n","#         # correct_items.append(solved_items)\n","#         # if any of the most recent correct counts are > 0 then save to a new folder\n","#         index = len(stats_obj[file])-1\n","#         if iterative_mode==\"chained models\" or stats_obj[file]['correct_counts'][index]>=correct_item_count_to_save_model or stats_obj[file]['correct_counts_bypred_len'][index]>=correct_item_count_to_save_model or stats_obj[file]['correct_counts_by_grid_size'][index]>=correct_item_count_to_save_model:\n","#             if iterative_mode==\"chained models\":\n","#                 model.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}\")\n","#                 tokenizer.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}\")\n","#             else:    \n","#                 model.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}_{stats_obj[file]['correct_counts'][index]}_{stats_obj[file]['correct_counts_bypred_len'][index]}_{stats_obj[file]['correct_counts_by_grid_size'][index]}\")\n","#                 tokenizer.save_pretrained(f\"{experiment_folder}/models/{epoch_current_count-epochs_to_train}_{stats_obj[file]['correct_counts'][index]}_{stats_obj[file]['correct_counts_bypred_len'][index]}_{stats_obj[file]['correct_counts_by_grid_size'][index]}\")\n","#         else:\n","#             model.save_pretrained(f\"{experiment_folder}\")\n","#             tokenizer.save_pretrained(f\"{experiment_folder}\")\n","#         save_data_and_stats(stats_obj, file)"]},{"cell_type":"markdown","metadata":{"id":"_dVMFVWyx3_G"},"source":["Load Model and run_inference (and supporting functions)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":3809,"status":"ok","timestamp":1665572457900,"user":{"displayName":"Jack Cole","userId":"15833472147952074131"},"user_tz":300},"id":"XRCLdqABLMaJ"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers import DataCollatorForSeq2Seq\n","\n","def load_model():\n","    global model, data_collator\n","    model = AutoModelForSeq2SeqLM.from_pretrained(model_to_fine_tune).to(device)\n","    print(\"model parameters: \"+str(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n","    # when it works, this causes the model to use a lot less memory\n","    if gradient_checkpointing:\n","        model.gradient_checkpointing_enable()\n","        model.encoder.gradient_checkpointing = True\n","        model.decoder.gradient_checkpointing = True\n","\n","    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n","\n","class SimpleDataset: # used to wrap the data for the evaluation phase\n","    def __init__(self, tokenized_texts):\n","        self.tokenized_texts = tokenized_texts\n","    \n","    def __len__(self):\n","        return len(self.tokenized_texts[\"input_ids\"])\n","    \n","    def __getitem__(self, idx):\n","        return {k: v[idx] for k, v in self.tokenized_texts.items()}\n","\n","def parse_out_grid(list_of_answers):\n","    grid_list = []\n","    for correct_answer in list_of_answers:\n","        correct_answer=correct_answer.strip().replace(\".\", \"\") #.replace(\" \", \"\").replace(\".\", \"\")\n","        correct_other_preds = correct_answer.split(\" \")[0:grid_starting_row]\n","        correct_len = int(correct_other_preds[0])\n","        #drop first item (length of answer)\n","        correct_other_preds = correct_other_preds[1:]\n","        #remove other preds from the correct answer\n","        correct_answer = correct_answer.split(\" \")[grid_starting_row:len(correct_answer.split(\" \"))]\n","        correct_answer = \" \".join(correct_answer)\n","        grid_list.append(correct_answer.strip())\n","    return grid_list\n","\n","def calc_accuracy(predictions, dataset_file, shuffle=True):\n","    # use calc character accuracy to calculate the accuracy of the predictions\n","    # parse the answer first\n","    # iterate through the predictions\n","    df = filter_file_for_max_tokens(dataset_file, shuffle)\n","    df['predictions'] = predictions\n","    results=[]\n","    for prediction in predictions:\n","        answer_no_non_programmatic_len_limit, answer_len_limit_by_prediction, answer_grid_size_by_prediction, output_len, other_preds, error = parse_answers_model1(prediction)\n","        results.append(answer_grid_size_by_prediction)\n","    df['results'] = results\n","    df['answer_grid'] = parse_out_grid(df['correct_answer'])\n","    df['accuracy'] = df.apply(lambda row: calculate_character_accuracy(row['answer_grid'], row['results']), axis=1)\n","    return df\n","\n","def run_inference(model, dataset_file, shuffle=True): # run a whole batch of prompts through the model\n","    print(\"===> Running inference...\")\n","    #tokenized_texts = tokenizer(prompt_strings, return_tensors=\"pt\")\n","    #test_dataset = SimpleDataset(tokenized_texts)\n","    test_dataset = load_and_process_dataset_from_file(dataset_file, shuffle)\n","    if deepspeed_enabled:\n","        training_args = Seq2SeqTrainingArguments(\n","            output_dir=\"./results\",\n","            evaluation_strategy=\"epoch\",\n","            per_device_train_batch_size=eval_batch_size,\n","            per_device_eval_batch_size=eval_batch_size,\n","            predict_with_generate=True,\n","            fp16=False,\n","            seed=42,\n","            deepspeed=f\"{experiment_folder}{deepspeed_config_file}\",\n","        )\n","    else:\n","        training_args = Seq2SeqTrainingArguments(\n","            output_dir=\"./results\",\n","            evaluation_strategy=\"epoch\",\n","            per_device_train_batch_size=eval_batch_size,\n","            per_device_eval_batch_size=eval_batch_size,\n","            predict_with_generate=True,\n","            fp16=False,\n","            seed=42,\n","        )\n","    trainer = Seq2SeqTrainer(\n","        model=model,\n","        args=training_args,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","    )\n","    result = {}\n","    result = trainer.predict(test_dataset, temperature=prediction_temp, max_length=max_output_length) #, max_length=512\n","    tokenizer.batch_decode(result.predictions, skip_special_tokens=True)\n","    predictions = tokenizer.batch_decode(result.predictions, skip_special_tokens=True)\n","    return calc_accuracy(predictions, dataset_file, shuffle)  # list of strings\n"]},{"cell_type":"markdown","metadata":{"id":"c4-cwCPmLMaK"},"source":["Train the Model"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1ba2a6c0d26f49418d82cf1e33e54a68","18a7244493ff419989a0ca891d99df3d","766f57101ddf4e268f16e7afd4b8979c","71ce75f236464d2189084b7dfacf3907","139542b095884c09adc51723548dd3e3","95f6587d79794e3eb4fdb1955de324a8","65ef4fe8e05f404e907aaa19c09ced4f","6c3e1b9cc4ce47d2b70810b35cdfdd8f","0ca50232d0254cd59af8e93074f0a3f1","7fbcad47fc9d46a4bdc7d3351d45b847","d48c3f2307804db39cdf3b02945ffaed","762143105db042c1b8195e834f7e5989","12290fbe21ff4ed5880f7bd1d0cacbd9","d4966a8dad4e44d080c1a8b99f936275","ece6332574f643df95a1a40e145c7402","ece673757e254d70b599562092290dd6","0567904d8db1405996ad30726cbcfe5a","c63d27f1393a47f0879effaeeadeab12","f184b5aaa065476686ee0b8961ce23ec","e6cfc8ac612c401585b31c9c28bea492","18e1bd61f3cd4f508808f7e3794736e4","515e2866eb5d408ebc2fdb02224c0f28"]},"id":"H2qr32poLMaK","outputId":"2bafa53c-b13b-4edb-a81a-3b8e59b9830c"},"outputs":[{"name":"stdout","output_type":"stream","text":["===> Loading model...\n","model parameters: 247587456\n","training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb6f5dd4dda24601b8c8ca0f53f3daf1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97a0fe58411e4e80ba824481251e45ff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"856bc33f0d624e23831e2a543a7dbca8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6941, 'learning_rate': 2.932757876564523e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-69500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6842, 'learning_rate': 2.7655157531290464e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-70000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6945, 'learning_rate': 2.5982736296935693e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-70500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6933, 'learning_rate': 2.4310315062580926e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-71000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6893, 'learning_rate': 2.2637893828226156e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-71500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6529, 'learning_rate': 2.0965472593871385e-05, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-72000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6833, 'learning_rate': 1.929305135951662e-05, 'epoch': 0.38}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-72500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6693, 'learning_rate': 1.7620630125161848e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-73000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6604, 'learning_rate': 1.5948208890807077e-05, 'epoch': 0.49}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-73500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6704, 'learning_rate': 1.427578765645231e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-74000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6566, 'learning_rate': 1.260336642209754e-05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6532, 'learning_rate': 1.0930945187742771e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6544, 'learning_rate': 9.258523953388002e-06, 'epoch': 0.7}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.659, 'learning_rate': 7.586102719033233e-06, 'epoch': 0.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6477, 'learning_rate': 5.913681484678464e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6316, 'learning_rate': 4.2412602503236945e-06, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.658, 'learning_rate': 2.5688390159689253e-06, 'epoch': 0.92}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6533, 'learning_rate': 8.964177816141563e-07, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37818331f3d6419e85fa1de80a1726f9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.8534314036369324, 'eval_runtime': 5.3661, 'eval_samples_per_second': 19.381, 'eval_steps_per_second': 2.423, 'epoch': 1.0}\n","{'train_runtime': 23654.7556, 'train_samples_per_second': 3.134, 'train_steps_per_second': 0.392, 'train_loss': 0.66602504402592, 'epoch': 1.0}\n","***** train metrics *****\n","  epoch                    =        1.0\n","  train_loss               =      0.666\n","  train_runtime            = 6:34:14.75\n","  train_samples            =      74137\n","  train_samples_per_second =      3.134\n","  train_steps_per_second   =      0.392\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98f78a998fde4267bba7f81ebf82bf4b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["***** eval metrics *****\n","  epoch                   =        1.0\n","  eval_loss               =     0.8534\n","  eval_runtime            = 0:00:05.33\n","  eval_samples            =        104\n","  eval_samples_per_second =     19.501\n","  eval_steps_per_second   =      2.438\n","===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e23a570ecdd47778bf1aba6a0702384","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caa2adfc9f6d4c1182f6c90c77f103d9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in .//models/3_4_4_56\\config.json\n","Model weights saved in .//models/3_4_4_56\\pytorch_model.bin\n","tokenizer config file saved in .//models/3_4_4_56\\tokenizer_config.json\n","Special tokens file saved in .//models/3_4_4_56\\special_tokens_map.json\n","Copy vocab file to .//models/3_4_4_56\\spiece.model\n"]},{"name":"stdout","output_type":"stream","text":["training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1013e11a5f9640baa4380f8095c4d831","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a1bbc2bcb504ca0ba525b5877d8cfd7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90d086672fba4e55b7813e6efefd4b94","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6784, 'learning_rate': 2.932757876564523e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6527, 'learning_rate': 2.7655157531290464e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6501, 'learning_rate': 2.5982736296935693e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6502, 'learning_rate': 2.4310315062580926e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6444, 'learning_rate': 2.2637893828226156e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6297, 'learning_rate': 2.0965472593871385e-05, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.614, 'learning_rate': 1.929305135951662e-05, 'epoch': 0.38}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6213, 'learning_rate': 1.7620630125161848e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6461, 'learning_rate': 1.5948208890807077e-05, 'epoch': 0.49}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6347, 'learning_rate': 1.427578765645231e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.624, 'learning_rate': 1.260336642209754e-05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6333, 'learning_rate': 1.0930945187742771e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6382, 'learning_rate': 9.258523953388002e-06, 'epoch': 0.7}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6189, 'learning_rate': 7.586102719033233e-06, 'epoch': 0.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6137, 'learning_rate': 5.913681484678464e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6097, 'learning_rate': 4.2412602503236945e-06, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6155, 'learning_rate': 2.5688390159689253e-06, 'epoch': 0.92}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5923, 'learning_rate': 8.964177816141563e-07, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8745771a100f40beb846a753da6f1bd6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.7930905818939209, 'eval_runtime': 10.0867, 'eval_samples_per_second': 10.311, 'eval_steps_per_second': 1.289, 'epoch': 1.0}\n","{'train_runtime': 31384.3317, 'train_samples_per_second': 2.362, 'train_steps_per_second': 0.295, 'train_loss': 0.6310337595143193, 'epoch': 1.0}\n","***** train metrics *****\n","  epoch                    =        1.0\n","  train_loss               =      0.631\n","  train_runtime            = 8:43:04.33\n","  train_samples            =      74137\n","  train_samples_per_second =      2.362\n","  train_steps_per_second   =      0.295\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58fe8ab579b340cc9776c42a1b292dd3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["***** eval metrics *****\n","  epoch                   =        1.0\n","  eval_loss               =     0.7931\n","  eval_runtime            = 0:00:10.25\n","  eval_samples            =        104\n","  eval_samples_per_second =     10.138\n","  eval_steps_per_second   =      1.267\n","===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"879c79c2b84749cbb0c95fe8bf3a1aad","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d49c6f8a51b44bfb9bd482bc09b9da5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in .//models/4_4_4_56\\config.json\n","Model weights saved in .//models/4_4_4_56\\pytorch_model.bin\n","tokenizer config file saved in .//models/4_4_4_56\\tokenizer_config.json\n","Special tokens file saved in .//models/4_4_4_56\\special_tokens_map.json\n","Copy vocab file to .//models/4_4_4_56\\spiece.model\n"]},{"name":"stdout","output_type":"stream","text":["training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc2dd7643b844b9596413c51f09c9670","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dfc43dc3295488fbc5520e8c1e07ce0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"025d8a52d4f248ed92ae234b4a3cc893","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5778, 'learning_rate': 2.932757876564523e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5566, 'learning_rate': 2.7655157531290464e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5593, 'learning_rate': 2.5982736296935693e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5628, 'learning_rate': 2.4310315062580926e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5601, 'learning_rate': 2.2637893828226156e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5532, 'learning_rate': 2.0965472593871385e-05, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5429, 'learning_rate': 1.929305135951662e-05, 'epoch': 0.38}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.554, 'learning_rate': 1.7620630125161848e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5806, 'learning_rate': 1.5948208890807077e-05, 'epoch': 0.49}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5739, 'learning_rate': 1.427578765645231e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5682, 'learning_rate': 1.260336642209754e-05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5821, 'learning_rate': 1.0930945187742771e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5913, 'learning_rate': 9.258523953388002e-06, 'epoch': 0.7}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5773, 'learning_rate': 7.586102719033233e-06, 'epoch': 0.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5762, 'learning_rate': 5.913681484678464e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5779, 'learning_rate': 4.2412602503236945e-06, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5866, 'learning_rate': 2.5688390159689253e-06, 'epoch': 0.92}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5686, 'learning_rate': 8.964177816141563e-07, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49ee2aaeff214d2dbdc9ded9784bec6a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.7902448177337646, 'eval_runtime': 5.3229, 'eval_samples_per_second': 19.538, 'eval_steps_per_second': 2.442, 'epoch': 1.0}\n","{'train_runtime': 19301.2742, 'train_samples_per_second': 3.841, 'train_steps_per_second': 0.48, 'train_loss': 0.5701417655434442, 'epoch': 1.0}\n","***** train metrics *****\n","  epoch                    =        1.0\n","  train_loss               =     0.5701\n","  train_runtime            = 5:21:41.27\n","  train_samples            =      74137\n","  train_samples_per_second =      3.841\n","  train_steps_per_second   =       0.48\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd1aee8d7f8848d284f0966081f5b118","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["***** eval metrics *****\n","  epoch                   =        1.0\n","  eval_loss               =     0.7902\n","  eval_runtime            = 0:00:05.28\n","  eval_samples            =        104\n","  eval_samples_per_second =     19.667\n","  eval_steps_per_second   =      2.458\n","===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e74b0cab3c48415e83fa369025b0c93b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d722653cb72c482e9cc60a6cc3eb4e87","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in .//models/5_4_4_56\\config.json\n","Model weights saved in .//models/5_4_4_56\\pytorch_model.bin\n","tokenizer config file saved in .//models/5_4_4_56\\tokenizer_config.json\n","Special tokens file saved in .//models/5_4_4_56\\special_tokens_map.json\n","Copy vocab file to .//models/5_4_4_56\\spiece.model\n"]},{"name":"stdout","output_type":"stream","text":["training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"854999664d4b44efa1c3f4104ef8ee5f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56bbb5fae4a14ae9bf3fda288ae3aa6c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a43c6e7c1a34ec8aa5d5d1441090572","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4861, 'learning_rate': 2.932757876564523e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4694, 'learning_rate': 2.7655157531290464e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4768, 'learning_rate': 2.5982736296935693e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4842, 'learning_rate': 2.4310315062580926e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4847, 'learning_rate': 2.2637893828226156e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4844, 'learning_rate': 2.0965472593871385e-05, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4794, 'learning_rate': 1.929305135951662e-05, 'epoch': 0.38}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4934, 'learning_rate': 1.7620630125161848e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5227, 'learning_rate': 1.5948208890807077e-05, 'epoch': 0.49}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5209, 'learning_rate': 1.427578765645231e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5209, 'learning_rate': 1.260336642209754e-05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5389, 'learning_rate': 1.0930945187742771e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5523, 'learning_rate': 9.258523953388002e-06, 'epoch': 0.7}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5429, 'learning_rate': 7.586102719033233e-06, 'epoch': 0.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5473, 'learning_rate': 5.913681484678464e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5533, 'learning_rate': 4.2412602503236945e-06, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.566, 'learning_rate': 2.5688390159689253e-06, 'epoch': 0.92}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5528, 'learning_rate': 8.964177816141563e-07, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecbd73097379495e8b3943cbc79db913","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.7940908074378967, 'eval_runtime': 5.2629, 'eval_samples_per_second': 19.761, 'eval_steps_per_second': 2.47, 'epoch': 1.0}\n","{'train_runtime': 18553.3591, 'train_samples_per_second': 3.996, 'train_steps_per_second': 0.5, 'train_loss': 0.5173313238006447, 'epoch': 1.0}\n","***** train metrics *****\n","  epoch                    =        1.0\n","  train_loss               =     0.5173\n","  train_runtime            = 5:09:13.35\n","  train_samples            =      74137\n","  train_samples_per_second =      3.996\n","  train_steps_per_second   =        0.5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6a09466a3d04c31bdedd1bba0b81fbc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["***** eval metrics *****\n","  epoch                   =        1.0\n","  eval_loss               =     0.7941\n","  eval_runtime            = 0:00:05.47\n","  eval_samples            =        104\n","  eval_samples_per_second =     18.989\n","  eval_steps_per_second   =      2.374\n","===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0aad795c91c34639896617734857c06e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e8651cb47274fbabcf41e221b3d61ad","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in .//models/6_4_4_55\\config.json\n","Model weights saved in .//models/6_4_4_55\\pytorch_model.bin\n","tokenizer config file saved in .//models/6_4_4_55\\tokenizer_config.json\n","Special tokens file saved in .//models/6_4_4_55\\special_tokens_map.json\n","Copy vocab file to .//models/6_4_4_55\\spiece.model\n"]},{"name":"stdout","output_type":"stream","text":["training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53e27b11cbbd474a838917cf7f15df8e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1762128741ea463dbce7fda636e0072a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48bf8b30631b42b0a4a566b0de5a28e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3991, 'learning_rate': 2.932757876564523e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3876, 'learning_rate': 2.7655157531290464e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3999, 'learning_rate': 2.5982736296935693e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.41, 'learning_rate': 2.4310315062580926e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4146, 'learning_rate': 2.2637893828226156e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4191, 'learning_rate': 2.0965472593871385e-05, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4198, 'learning_rate': 1.929305135951662e-05, 'epoch': 0.38}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4365, 'learning_rate': 1.7620630125161848e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4687, 'learning_rate': 1.5948208890807077e-05, 'epoch': 0.49}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4722, 'learning_rate': 1.427578765645231e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4778, 'learning_rate': 1.260336642209754e-05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5001, 'learning_rate': 1.0930945187742771e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5181, 'learning_rate': 9.258523953388002e-06, 'epoch': 0.7}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5135, 'learning_rate': 7.586102719033233e-06, 'epoch': 0.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5231, 'learning_rate': 5.913681484678464e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5343, 'learning_rate': 4.2412602503236945e-06, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5514, 'learning_rate': 2.5688390159689253e-06, 'epoch': 0.92}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5431, 'learning_rate': 8.964177816141563e-07, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f33aec0cab646be8ddec74dd47c59da","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.8019554615020752, 'eval_runtime': 5.4535, 'eval_samples_per_second': 19.07, 'eval_steps_per_second': 2.384, 'epoch': 1.0}\n","{'train_runtime': 18056.0758, 'train_samples_per_second': 4.106, 'train_steps_per_second': 0.513, 'train_loss': 0.4692811402052088, 'epoch': 1.0}\n","***** train metrics *****\n","  epoch                    =        1.0\n","  train_loss               =     0.4693\n","  train_runtime            = 5:00:56.07\n","  train_samples            =      74137\n","  train_samples_per_second =      4.106\n","  train_steps_per_second   =      0.513\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcedf435706547b1adb1766fcc2792bc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["***** eval metrics *****\n","  epoch                   =        1.0\n","  eval_loss               =      0.802\n","  eval_runtime            = 0:00:05.37\n","  eval_samples            =        104\n","  eval_samples_per_second =     19.342\n","  eval_steps_per_second   =      2.418\n","===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c903aea5bfb4e638de7648886120dae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e367eabc4d2345cca2c1d1d274aadfb7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in .//models/7_5_5_55\\config.json\n","Model weights saved in .//models/7_5_5_55\\pytorch_model.bin\n","tokenizer config file saved in .//models/7_5_5_55\\tokenizer_config.json\n","Special tokens file saved in .//models/7_5_5_55\\special_tokens_map.json\n","Copy vocab file to .//models/7_5_5_55\\spiece.model\n"]},{"name":"stdout","output_type":"stream","text":["training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea95e408d57c4fc191165539d1695548","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f8313e63daa4c6b938a2f582356cf70","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f65219db5f2f4593aa19c038bf53704c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3205, 'learning_rate': 2.932757876564523e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3152, 'learning_rate': 2.7655157531290464e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.33, 'learning_rate': 2.5982736296935693e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3405, 'learning_rate': 2.4310315062580926e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.349, 'learning_rate': 2.2637893828226156e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3573, 'learning_rate': 2.0965472593871385e-05, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3633, 'learning_rate': 1.929305135951662e-05, 'epoch': 0.38}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3811, 'learning_rate': 1.7620630125161848e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.416, 'learning_rate': 1.5948208890807077e-05, 'epoch': 0.49}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4249, 'learning_rate': 1.427578765645231e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4359, 'learning_rate': 1.260336642209754e-05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4628, 'learning_rate': 1.0930945187742771e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.486, 'learning_rate': 9.258523953388002e-06, 'epoch': 0.7}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4863, 'learning_rate': 7.586102719033233e-06, 'epoch': 0.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5019, 'learning_rate': 5.913681484678464e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5183, 'learning_rate': 4.2412602503236945e-06, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5398, 'learning_rate': 2.5688390159689253e-06, 'epoch': 0.92}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5371, 'learning_rate': 8.964177816141563e-07, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8bb90242078a47bca8775fe8085211a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.8098087310791016, 'eval_runtime': 5.431, 'eval_samples_per_second': 19.149, 'eval_steps_per_second': 2.394, 'epoch': 1.0}\n","{'train_runtime': 18791.5169, 'train_samples_per_second': 3.945, 'train_steps_per_second': 0.493, 'train_loss': 0.42484201292154034, 'epoch': 1.0}\n","***** train metrics *****\n","  epoch                    =        1.0\n","  train_loss               =     0.4248\n","  train_runtime            = 5:13:11.51\n","  train_samples            =      74137\n","  train_samples_per_second =      3.945\n","  train_steps_per_second   =      0.493\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99c497f6b86d4455aeb460660528d90a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["***** eval metrics *****\n","  epoch                   =        1.0\n","  eval_loss               =     0.8098\n","  eval_runtime            = 0:00:05.31\n","  eval_samples            =        104\n","  eval_samples_per_second =     19.574\n","  eval_steps_per_second   =      2.447\n","===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d04b47917248417d89390324aa53b515","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7af77ad4a01b481a82507ca09ad82e2e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in .//models/8_5_5_56\\config.json\n","Model weights saved in .//models/8_5_5_56\\pytorch_model.bin\n","tokenizer config file saved in .//models/8_5_5_56\\tokenizer_config.json\n","Special tokens file saved in .//models/8_5_5_56\\special_tokens_map.json\n","Copy vocab file to .//models/8_5_5_56\\spiece.model\n"]},{"name":"stdout","output_type":"stream","text":["training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86cb2435cd3c43beb93c283c85ee1230","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66fab3cebce44ba1ae730e40102c6714","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"324a8f9b14a346b08092fe4829423c48","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.2542, 'learning_rate': 2.932757876564523e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.2556, 'learning_rate': 2.7655157531290464e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.2701, 'learning_rate': 2.5982736296935693e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.2795, 'learning_rate': 2.4310315062580926e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.2898, 'learning_rate': 2.2637893828226156e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.2999, 'learning_rate': 2.0965472593871385e-05, 'epoch': 0.32}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3087, 'learning_rate': 1.929305135951662e-05, 'epoch': 0.38}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3272, 'learning_rate': 1.7620630125161848e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3626, 'learning_rate': 1.5948208890807077e-05, 'epoch': 0.49}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.378, 'learning_rate': 1.427578765645231e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.3938, 'learning_rate': 1.260336642209754e-05, 'epoch': 0.59}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-5500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4261, 'learning_rate': 1.0930945187742771e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4543, 'learning_rate': 9.258523953388002e-06, 'epoch': 0.7}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-6500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-1500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4606, 'learning_rate': 7.586102719033233e-06, 'epoch': 0.76}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4819, 'learning_rate': 5.913681484678464e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-7500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-2500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5039, 'learning_rate': 4.2412602503236945e-06, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5303, 'learning_rate': 2.5688390159689253e-06, 'epoch': 0.92}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-8500\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-3500] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","Saving model checkpoint to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\n","Configuration saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5332, 'learning_rate': 8.964177816141563e-07, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\pytorch_model.bin\n","tokenizer config file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\tokenizer_config.json\n","Special tokens file saved in ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\special_tokens_map.json\n","Copy vocab file to ./resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-9000\\spiece.model\n","Deleting older checkpoint [resultsACW_2022_10_15_1_ARC_180M_DATASET_LT5\\checkpoint-4000] due to args.save_total_limit\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59db513762e047438bfc0fe185f32231","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 104\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.8185641169548035, 'eval_runtime': 5.317, 'eval_samples_per_second': 19.56, 'eval_steps_per_second': 2.445, 'epoch': 1.0}\n","{'train_runtime': 18820.6421, 'train_samples_per_second': 3.939, 'train_steps_per_second': 0.492, 'train_loss': 0.38409293845238024, 'epoch': 1.0}\n","***** train metrics *****\n","  epoch                    =        1.0\n","  train_loss               =     0.3841\n","  train_runtime            = 5:13:40.64\n","  train_samples            =      74137\n","  train_samples_per_second =      3.939\n","  train_steps_per_second   =      0.492\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"480eee2959c841608acb1530ccdefdfe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["***** eval metrics *****\n","  epoch                   =        1.0\n","  eval_loss               =     0.8186\n","  eval_runtime            = 0:00:05.28\n","  eval_samples            =        104\n","  eval_samples_per_second =     19.674\n","  eval_steps_per_second   =      2.459\n","===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6222fd8dd8e439ebd5612cf7f9fc419","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"023fab606d03449694b4f67c14682a26","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]},{"name":"stderr","output_type":"stream","text":["Configuration saved in .//models/9_3_3_56\\config.json\n","Model weights saved in .//models/9_3_3_56\\pytorch_model.bin\n","tokenizer config file saved in .//models/9_3_3_56\\tokenizer_config.json\n","Special tokens file saved in .//models/9_3_3_56\\special_tokens_map.json\n","Copy vocab file to .//models/9_3_3_56\\spiece.model\n"]},{"name":"stdout","output_type":"stream","text":["training for 1 epochs with batch size 8\n","create_new_iterative_training_dataset\n","load_and_process_dataset_from_file ./train_with_letters_none_noise.csv\n","filter_file_for_max_tokens ./train_with_letters_none_noise.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4421b25ba6cf49d4b3bb8f5e0f6b8c7b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/75 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ac37563803c4a2bbb6e9efece0c0d7f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The following columns in the training set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count. If correct_answer, token_count_correct, id, path_data, augmentation, number_to_replace_list, replace_with_list, prompt, token_count are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 74137\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9268\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f989d0718264cf6908b6c0c2eb30b98","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9268 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Acer\\Desktop\\ARC Challenge\\Experiments\\Experiment ACW - Colab DL 180M Dataset for ARC\\ACW Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m epochs \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch_start\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, epoch_end, epoch_step):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     epoch_current_count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mepoch_step\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     train_for_epochs_and_calc_totals(epoch_step, epoch_current_count, stats_obj)\n","\u001b[1;32mc:\\Users\\Acer\\Desktop\\ARC Challenge\\Experiments\\Experiment ACW - Colab DL 180M Dataset for ARC\\ACW Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb Cell 34\u001b[0m in \u001b[0;36mtrain_for_epochs_and_calc_totals\u001b[1;34m(epochs_to_train, epoch_current_count, stats_obj)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39m#trainer.evaluate()\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m train_result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m save_metrics(trainer, train_result, tokenized_train, tokenized_eval)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X45sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m \u001b[39m# iterate through the evaluation files\u001b[39;00m\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\trainer.py:1498\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1495\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1497\u001b[0m )\n\u001b[1;32m-> 1498\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1499\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1500\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1501\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1502\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1503\u001b[0m )\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\trainer.py:1740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1739\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1740\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1743\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1744\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1745\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1746\u001b[0m ):\n\u001b[0;32m   1747\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\trainer.py:2488\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2486\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39mbackward(loss)\n\u001b[0;32m   2487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2488\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m   2490\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach()\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["stats_obj = {}\n","# make an array for each of the evaluation_files\n","for evaluation_file in evaluation_files:\n","    stats_obj[evaluation_file] = pd.DataFrame(columns=['epoch', 'correct_counts', 'correct_counts_len', 'correct_counts_bypred_len', 'correct_counts_pred_len', 'correct_counts_by_grid_size', 'correct_counts_other_preds', 'character_level_accuracy', 'character_level_accuracy_by_grid_size_pred', 'character_level_accuracy_by_len_pred', 'character_level_accuracy_by_len_actual', 'row_level_accuracy_ordered', 'row_level_accuracy_unordered', 'correct_items'])\n","\n","# correct_counts=[]\n","# correct_counts_len=[]\n","# correct_counts_bypred_len=[]\n","# correct_counts_pred_len=[]\n","# correct_counts_other_preds=[]\n","# correct_counts_by_grid_size=[]\n","# character_level_accuracy=[]\n","# character_level_accuracy_by_grid_size_pred=[]\n","# character_level_accuracy_by_len_pred=[]\n","# character_level_accuracy_by_len_actual=[]\n","# row_level_accuracy_ordered=[]\n","# row_level_accuracy_unordered=[]\n","# correct_items=[]\n","accuracy_threshold_to_iterate_current = accuracy_threshold_to_iterate_start\n","epoch_current=[]\n","\n","if iterative_mode!='chained models':\n","    print(\"===> Loading model...\")\n","    load_model()\n","\n","if epoch_start_up>0:\n","    epoch_current_count=epoch_start_up\n","    train_for_epochs_and_calc_totals(epoch_start_up, epoch_current_count, stats_obj)\n","\n","for epochs in range(epoch_start+1, epoch_end, epoch_step):\n","    epoch_current_count+=epoch_step\n","    train_for_epochs_and_calc_totals(epoch_step, epoch_current_count, stats_obj)\n","\n","\n","#learn.validate(1, dl=None, cbs=fit_cbs)"]},{"cell_type":"markdown","metadata":{"id":"YtBQhP5vLMaK"},"source":["# Run all above cells for fine tuning.  The cells below can be used to resume training if it is stopped\n","\n","# Tools Below"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6AWzTGf2LMaK"},"outputs":[],"source":["# this will print results\n","# other results files are saved in the experiment folder in csv format for each epoch_step with a file name of {model_name_safe}_{epoch_current_count}_epochs_batchsize_1_results.csv\n","# if you train to the end, the final results will be saved in a file called {model_name_safe}_final_results.csv\n","\n","# Print results for each evaluation file\n","for file in evaluation_files:\n","    print(f\"===> Results for {file}\")\n","    print(stats_obj[file])\n","    print(f\"Correct counts: {stats_obj[file]['correct_counts']}\")\n","    print(f\"Correct counts by len: {stats_obj[file]['correct_counts_len']}\")\n","    print(f\"Correct counts by pred len: {stats_obj[file]['correct_counts_bypred_len']}\")\n","    print(f\"Correct counts by grid size: {stats_obj[file]['correct_counts_by_grid_size']}\")\n","    print(f\"Correct prediction of length: {stats_obj[file]['correct_counts_pred_len']}\")\n","    print(f\"Correct other predictions: {stats_obj[file]['correct_counts_other_preds']}\")\n","    print(f\"Correct items: {stats_obj[file]['correct_items']}\")\n","# summary stats\n","\n","    #print the headers\n","    print(f\"model_name,epoch_start,epoch_end,epoch_step,batch_size,lr,epoch_step\")\n","    print(f\"{model_to_fine_tune},{epoch_start},{epoch_end},{epoch_step},{batch_size},{lr},{epoch_step}\")\n","\n","    # iterate through the correct_counts and print the results\n","    correct_other_preds_column_titles = repeat_string_with_comma(\"other_preds_string\", grid_starting_row-1)\n","    print(f\"epoch,correct_count,correct_count_by_len,correct_by_pred_len,correct_pred_len,correct_answer_by_grid_size,\"+correct_other_preds_column_titles+\",cell_level_accuracy,cell_level_accuracy_by_grid_size_pred,cell_level_accuracy_by_pred_len,cell_level_accuracy_by_correct_ans_len,row_level_accuracy_ordered,row_level_accuracy_unordered,solved_items\\n\")\n","    for i in range(len(stats_obj[file]['correct_counts'])):\n","        epochval=epoch_current[i]\n","        try:\n","            curr_pred_len_correct=stats_obj[file]['correct_counts_pred_len'][i]\n","        except:\n","            curr_pred_len_correct=0\n","        print(f\"{epochval},{stats_obj[file]['correct_counts'][i]},{stats_obj[file]['correct_counts_len'][i]},{stats_obj[file]['correct_counts_bypred_len'][i]},{stats_obj[file]['correct_counts_pred_len'][i]},{stats_obj[file]['correct_counts_by_grid_size'][i]},{stats_obj[file]['correct_counts_other_preds'][i]},{stats_obj[file]['character_level_accuracy'][i]},{stats_obj[file]['character_level_accuracy_by_grid_size_pred'][i]},{stats_obj[file]['character_level_accuracy_by_len_pred'][i]},{stats_obj[file]['character_level_accuracy_by_len_actual'][i]},{stats_obj[file]['row_level_accuracy_ordered'][i]},{stats_obj[file]['row_level_accuracy_unordered'][i]},{','.join(stats_obj[file]['correct_items'][i])}\\n\")\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"N5mfzMwwx3_I"},"source":["# Visualize Solved Items"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3shE-Pnix3_J"},"outputs":[],"source":["# #correct_items = [[\"3b4c2228_0\"],[\"3b4c2228_0\", \"358ba94e_0\", \"1a2e2828_0\"], [\"3b4c2228_0\"]]\n","\n","# unique_correct_items=[]\n","\n","# # iterate through the evaluation files and get the unique correct items\n","# for file in evaluation_files:\n","#     for item in stats_obj[file]['correct_items']:\n","#         for i in item:\n","#             if i not in unique_correct_items:\n","#                 unique_correct_items.append(i)\n","#                 # plot the riddle\n","#                 riddle = load_riddle_from_id(i.split(\"_\")[-2].split(\"/\")[-1])\n","#                 plot_task(riddle)\n","                \n","# # # set correct_items list equal to the \"correct_items\" column of stats_obj[file]\n","# # # iterate through correct items\n","# # for i in range(len(correct_items)):\n","# #     # get the correct items\n","# #     correct_items_for_epoch = correct_items[i]\n","# #     for correct_item in correct_items_for_epoch:\n","# #         if correct_item not in unique_correct_items:\n","# #             unique_correct_items.append(correct_item)\n","\n","# # # iterate through the unique correct items\n","# # for unique_correct_item in unique_correct_items:\n","# #     riddle = load_riddle_from_id(unique_correct_item.split(\"_\")[0])\n","# #     plot_task(riddle)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbBXbvaRLMaK"},"outputs":[],"source":["# use this to continue training if the above cell fails or is stopped before completion\n","'''epoch_start=80\n","epoch_current=[]\n","epoch_current_count=epoch_start'''\n","#lr = 5e-4 # learning rate\n","\"\"\" epoch_start=2\n","epoch_current_count=epoch_start\n","for epochs in range(epoch_start+1, epoch_end, epoch_step):\n","    epoch_current_count+=epoch_step\n","    train_for_epochs_and_calc_totals(epoch_step, epoch_current_count, stats_obj)\n","    # need to add iteration through evaluation files\n","    save_data_and_stats(stats_obj) \"\"\""]},{"cell_type":"markdown","metadata":{"id":"5lzifhKVLMaL"},"source":["If you stop training early, you can use the below to run the model against the validation dataset and it will save the results to a file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7B_l1CQ_LMaL"},"outputs":[{"name":"stdout","output_type":"stream","text":["===> Running inference...\n","load_and_process_dataset_from_file ./eval_data_none.csv\n","filter_file_for_max_tokens ./eval_data_none.csv\n","loading dataset from pandas dataframe\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13d9eb807f644b1da1daa87c376dbbb5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set don't have a corresponding argument in `LongT5ForConditionalGeneration.forward` and have been ignored: token_count_correct, id, number_to_replace_list, augmentation, prompt, token_count, replace_with_list, correct_answer. If token_count_correct, id, number_to_replace_list, augmentation, prompt, token_count, replace_with_list, correct_answer are not expected by `LongT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 104\n","  Batch size = 20\n","c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:667: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06d2f4a857f64d05ab7733fd11c20429","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["filter_file_for_max_tokens ./eval_data_none.csv\n"]}],"source":["# iterate through the evaluation_files\n","#for file in evaluation_files:\n","#    get_and_save_predictions(model, file)"]},{"cell_type":"markdown","metadata":{"id":"CMsMv1c0LMaL"},"source":["If you stop in the middle of a training set, you can save the Huggingface model and tokenizer with the code below.  This model does work across platforms."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMEzIsgiLMaL"},"outputs":[],"source":["# clear gpu memory cache\n","#torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"XjEkFwkRLMaL"},"source":["# Manually save model\n","\n","If the training stops and you want to manually save the model, you can use the code below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4pz2e1k6fxU"},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in .//model\\config.json\n"]},{"ename":"RuntimeError","evalue":"CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Acer\\Desktop\\ARC Challenge\\Experiments\\Experiment ACW - Colab DL 180M Dataset for ARC\\ACW Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#use this to save the huggingface model and tokenizer\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49msave_pretrained(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mexperiment_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/model\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Acer/Desktop/ARC%20Challenge/Experiments/Experiment%20ACW%20-%20Colab%20DL%20180M%20Dataset%20for%20ARC/ACW%20Iteratively_Fine_tune_HF_model_for_ARC_challenge.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tokenizer\u001b[39m.\u001b[39msave_pretrained(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mexperiment_folder\u001b[39m}\u001b[39;00m\u001b[39m/model\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\modeling_utils.py:1563\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[1;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, **kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m \u001b[39mfor\u001b[39;00m shard_file, shard \u001b[39min\u001b[39;00m shards\u001b[39m.\u001b[39mitems():\n\u001b[1;32m-> 1563\u001b[0m     save_function(shard, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(save_directory, shard_file))\n\u001b[0;32m   1565\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1566\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel weights saved in \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_directory, WEIGHTS_NAME)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\serialization.py:379\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    378\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 379\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    380\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    381\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\serialization.py:601\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[39m# given that we copy things around anyway, we might use storage.cpu()\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[39m# this means to that to get tensors serialized, you need to implement\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m# .cpu() on the underlying Storage\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m storage\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 601\u001b[0m     storage \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mcpu()\n\u001b[0;32m    602\u001b[0m \u001b[39m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[0;32m    603\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\storage.py:112\u001b[0m, in \u001b[0;36m_StorageBase.cpu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_UntypedStorage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize())\u001b[39m.\u001b[39;49mcopy_(\u001b[39mself\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."]}],"source":["\n","#use this to save the huggingface model and tokenizer\n","model.save_pretrained(f\"{experiment_folder}/model\")\n","tokenizer.save_pretrained(f\"{experiment_folder}/model\")"]},{"cell_type":"markdown","metadata":{"id":"siCjE6PCLMaL"},"source":["# Features to add\n","\n","Display all answers so you can see the difference between the correct answer and the predicted answers.  Maybe show correct answer and then all 4 of the parsed answer variations (see the results file for the 4 columns that are after correct answer).  Maybe show items that meet a minimum accuracy threshold to see what the issues are."]},{"cell_type":"markdown","metadata":{"id":"Re6l1r_eLMaM"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajbTe5Plx3_L"},"outputs":[],"source":["#not using this function anymore. it is replaced by run_inference\n","def do_inference(model, input_text, return_error_status=True):\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","    error = False\n","    try:\n","        outputs = model.generate(input_ids, temperature=prediction_temp, num_beams=4, num_beam_groups=2, top_k=50, top_p=0.95, early_stopping=True, max_length=max_output_length, repetition_penalty=2.5)\n","    except IndexError:\n","        outputs = None\n","        error = True\n","        if return_error_status:\n","            return outputs, error\n","        else:\n","            return outputs\n","    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    # remove all characters that are not numbers, spaces, or commas\n","    decoded_output = re.sub(r\"[^0-9, ]\", \"\", decoded_output) + \".\"\n","    if return_error_status:\n","        return decoded_output, error\n","    else:\n","        return decoded_output\n","\n","#do_inference(model, \"train input1 10000 00020 output1 5 2 5 01 01000 00200. input2 01000 00200 output2 5 2 5 01 00100 02000. test tinput1 00100 00002 toutput1 \", return_error_status=True)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"c58e9361bde7ca617934da376e83056db506761bdc9593ca2087fabac973f609"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0567904d8db1405996ad30726cbcfe5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0685654a1dd6408c8f515da65ed5ddb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e85189bd1cc4247a95734f906fe0f71","placeholder":"​","style":"IPY_MODEL_567ca34370c0478f80f4867a782c801c","value":" 1.39M/1.39M [00:00&lt;00:00, 3.36MB/s]"}},"06c99d94254c43dd88eec57f52d5f8b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ca50232d0254cd59af8e93074f0a3f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e26b17557c94ce08550b3a6805e8cce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e82e5edfc77c43f0ad9113dd7dfa78f5","placeholder":"​","style":"IPY_MODEL_2de44597f25c4c4ca6fc1051062cb9bb","value":" 0/0 [00:00&lt;?, ?it/s]"}},"12290fbe21ff4ed5880f7bd1d0cacbd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0567904d8db1405996ad30726cbcfe5a","placeholder":"​","style":"IPY_MODEL_c63d27f1393a47f0879effaeeadeab12","value":"100%"}},"139542b095884c09adc51723548dd3e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18454d9db3d74bbe9367060bf88513db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18a7244493ff419989a0ca891d99df3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95f6587d79794e3eb4fdb1955de324a8","placeholder":"​","style":"IPY_MODEL_65ef4fe8e05f404e907aaa19c09ced4f","value":"100%"}},"18e1bd61f3cd4f508808f7e3794736e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ba2a6c0d26f49418d82cf1e33e54a68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18a7244493ff419989a0ca891d99df3d","IPY_MODEL_766f57101ddf4e268f16e7afd4b8979c","IPY_MODEL_71ce75f236464d2189084b7dfacf3907"],"layout":"IPY_MODEL_139542b095884c09adc51723548dd3e3"}},"1f4ce4e9beb143e68016c72d9c2c75f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb34d70eaf6461bbdba36db45a2999a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4db5e63b7d624e9c8ab4a9d98005f269","max":851,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18454d9db3d74bbe9367060bf88513db","value":851}},"24b3344c6dd242f2bcf788f87cd6ea54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b1b22a2c5e84da3a698d9afe8f13c0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2de44597f25c4c4ca6fc1051062cb9bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4215bf0484f9460dbee73d48f5cb5c8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_caf290bdd1ab47f1bc62ab724cb5b3e9","IPY_MODEL_1fb34d70eaf6461bbdba36db45a2999a","IPY_MODEL_6159d356f3644cfbbf317fef27756d61"],"layout":"IPY_MODEL_96dbe96fec8d4df29f82bb979096428e"}},"445103f567a64ba783753d0b90a32f6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24b3344c6dd242f2bcf788f87cd6ea54","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e28d373b0fb24da29b7e7f1b35691b3f","value":791656}},"484209402e6a4ee4b86ccc0775305e62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4db5e63b7d624e9c8ab4a9d98005f269":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"515e2866eb5d408ebc2fdb02224c0f28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"567ca34370c0478f80f4867a782c801c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c390ba7b5c843faa7284fb3ffc309c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6159d356f3644cfbbf317fef27756d61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67c17f8656904c7a9c0c23b53a5fedae","placeholder":"​","style":"IPY_MODEL_484209402e6a4ee4b86ccc0775305e62","value":" 851/851 [00:00&lt;00:00, 32.1kB/s]"}},"65ef4fe8e05f404e907aaa19c09ced4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"661542f02b0d4858b1925431dad913a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67c17f8656904c7a9c0c23b53a5fedae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c3e1b9cc4ce47d2b70810b35cdfdd8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71ce75f236464d2189084b7dfacf3907":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fbcad47fc9d46a4bdc7d3351d45b847","placeholder":"​","style":"IPY_MODEL_d48c3f2307804db39cdf3b02945ffaed","value":" 75/75 [00:58&lt;00:00,  1.74ba/s]"}},"762143105db042c1b8195e834f7e5989":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12290fbe21ff4ed5880f7bd1d0cacbd9","IPY_MODEL_d4966a8dad4e44d080c1a8b99f936275","IPY_MODEL_ece6332574f643df95a1a40e145c7402"],"layout":"IPY_MODEL_ece673757e254d70b599562092290dd6"}},"766f57101ddf4e268f16e7afd4b8979c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c3e1b9cc4ce47d2b70810b35cdfdd8f","max":75,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ca50232d0254cd59af8e93074f0a3f1","value":75}},"78ad2485f6d54e179631359e6db52d11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ccf95c50f8147509c871dcaef5c90bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d6e024958ac4cf5ae59041d82299da4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f9f8edbd5f849f982252de0a6499f7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efb87782971d437db2bd3ad833026a38","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ccf95c50f8147509c871dcaef5c90bb","value":1389353}},"7fbcad47fc9d46a4bdc7d3351d45b847":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b67479e467d4f2aa466e2c595f6c914":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f39570f3223f4e079111d3cda6dbb6ca","IPY_MODEL_445103f567a64ba783753d0b90a32f6b","IPY_MODEL_be0828e04c074671a3d496273c5d15b8"],"layout":"IPY_MODEL_06c99d94254c43dd88eec57f52d5f8b7"}},"8e85189bd1cc4247a95734f906fe0f71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b968b6a511495d8443cc5ad3277b14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_daf1dca873d34433b8f92a85d9c433f0","IPY_MODEL_7f9f8edbd5f849f982252de0a6499f7c","IPY_MODEL_0685654a1dd6408c8f515da65ed5ddb9"],"layout":"IPY_MODEL_de68bc057a8b426c8a0d810beb28180d"}},"95f6587d79794e3eb4fdb1955de324a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96dbe96fec8d4df29f82bb979096428e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b37d4a60d04c8280188745d8f31b23":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b79bcbe963f4440ca4cfea35cd191f0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba873aeb8c0448519a23dcd7198220fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c733ea5cf8fe4b8c89a097271eff5589","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3c7b8b8ef764040a5f69df7e76ab7b1","value":0}},"be0828e04c074671a3d496273c5d15b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f4ce4e9beb143e68016c72d9c2c75f1","placeholder":"​","style":"IPY_MODEL_2b1b22a2c5e84da3a698d9afe8f13c0b","value":" 792k/792k [00:00&lt;00:00, 2.51MB/s]"}},"c63d27f1393a47f0879effaeeadeab12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c733ea5cf8fe4b8c89a097271eff5589":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"caf290bdd1ab47f1bc62ab724cb5b3e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb4bdf1b21cd42b9af41d7671ce8e18d","placeholder":"​","style":"IPY_MODEL_5c390ba7b5c843faa7284fb3ffc309c6","value":"Downloading: 100%"}},"d48c3f2307804db39cdf3b02945ffaed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4966a8dad4e44d080c1a8b99f936275":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f184b5aaa065476686ee0b8961ce23ec","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6cfc8ac612c401585b31c9c28bea492","value":1}},"daf1dca873d34433b8f92a85d9c433f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1b37d4a60d04c8280188745d8f31b23","placeholder":"​","style":"IPY_MODEL_7d6e024958ac4cf5ae59041d82299da4","value":"Downloading: 100%"}},"de68bc057a8b426c8a0d810beb28180d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0ddd5f1ae2e428690721cc983e008ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e28d373b0fb24da29b7e7f1b35691b3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e685dc60ac4944c4874ef51ee1f17303":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f81aab2ac1c44c8cb845b5930b439821","IPY_MODEL_ba873aeb8c0448519a23dcd7198220fa","IPY_MODEL_0e26b17557c94ce08550b3a6805e8cce"],"layout":"IPY_MODEL_b79bcbe963f4440ca4cfea35cd191f0a"}},"e6cfc8ac612c401585b31c9c28bea492":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e82e5edfc77c43f0ad9113dd7dfa78f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4bdf1b21cd42b9af41d7671ce8e18d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebcfb85334fa4168986c40c4e34949d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece6332574f643df95a1a40e145c7402":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18e1bd61f3cd4f508808f7e3794736e4","placeholder":"​","style":"IPY_MODEL_515e2866eb5d408ebc2fdb02224c0f28","value":" 1/1 [00:00&lt;00:00,  9.34ba/s]"}},"ece673757e254d70b599562092290dd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb87782971d437db2bd3ad833026a38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f184b5aaa065476686ee0b8961ce23ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f39570f3223f4e079111d3cda6dbb6ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebcfb85334fa4168986c40c4e34949d6","placeholder":"​","style":"IPY_MODEL_78ad2485f6d54e179631359e6db52d11","value":"Downloading: 100%"}},"f3c7b8b8ef764040a5f69df7e76ab7b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f81aab2ac1c44c8cb845b5930b439821":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0ddd5f1ae2e428690721cc983e008ff","placeholder":"​","style":"IPY_MODEL_661542f02b0d4858b1925431dad913a7","value":""}}}}},"nbformat":4,"nbformat_minor":0}
